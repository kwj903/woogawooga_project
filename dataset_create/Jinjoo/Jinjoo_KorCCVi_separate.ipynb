{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3832822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 파일 'github_dataset.csv'을 불러옵니다...\n",
      "\n",
      "✅ 원본 파일 로드 성공!\n",
      "데이터프레임 정보:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2927 entries, 0 to 2926\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   id          2927 non-null   int64  \n",
      " 1   transcript  2927 non-null   object \n",
      " 2   confidence  0 non-null      float64\n",
      " 3   label       2927 non-null   int64  \n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 91.6+ KB\n",
      "\n",
      "전체 행 개수: 2927\n",
      "\n",
      "데이터 미리보기:\n",
      "       id                                         transcript  confidence  \\\n",
      "2922  690  지금까지 사실확인서를 연락드렸습니다. 하고 있는데 이런 사건 때문에 내가 여쭤볼게 ...         NaN   \n",
      "2923  691  연료 데이는 사건 때문에 연락 드렸는데 혹시 김명철씨 가십니까 모르시고 아는 사람도...         NaN   \n",
      "2924  692  4장 4절 일어났습니까? 장소 잡고 님께서는 42세 남성 김동술 알고 계십니까? 아...         NaN   \n",
      "2925  693  네\\n네 여보세요\\n뭐 어디세요?\\n아 네 안녕하세요 저희 그 하나캐피탈에서 연락을...         NaN   \n",
      "2926  694  통장명이 (삐-) 계좌 맞구요? 그리고 통장 발급 일은 2017년 3월 14일입니다...         NaN   \n",
      "\n",
      "      label  \n",
      "2922      1  \n",
      "2923      1  \n",
      "2924      1  \n",
      "2925      1  \n",
      "2926      1  \n"
     ]
    }
   ],
   "source": [
    "# ==================================================================================\n",
    "# Pandas를 이용한 CSV 파일 로드 및 기본 정보 확인 스크립트\n",
    "# ==================================================================================\n",
    "#\n",
    "# [ 주요 기능 ]\n",
    "# 1. CSV 파일 로드: Pandas 라이브러리의 `read_csv` 함수를 사용하여 지정된 CSV 파일을\n",
    "#    데이터프레임(DataFrame) 형태로 불러옵니다.\n",
    "#    - `engine=\"python\"` 옵션은 파일 경로에 한글이 포함되거나 파싱 오류가 발생할 때\n",
    "#      안정적으로 파일을 읽도록 돕습니다.\n",
    "# 2. 데이터 구조 확인: `df.info()` 메서드를 호출하여 데이터프레임의 전체적인 정보를\n",
    "#    출력합니다. (전체 행 개수, 각 열의 데이터 타입, 누락되지 않은 값의 개수 등)\n",
    "# 3. 데이터 미리보기: `df.tail()` 메서드를 사용하여 데이터의 마지막 5개 행을 출력,\n",
    "#    데이터가 어떻게 구성되어 있는지 빠르게 확인합니다.\n",
    "# 4. 오류 처리: `try-except` 구문을 사용하여 파일을 찾을 수 없는 경우(FileNotFoundError)나\n",
    "#    기타 예외가 발생했을 때, 프로그램이 중단되지 않고 적절한 오류 메시지를\n",
    "#    출력하도록 처리합니다.\n",
    "#\n",
    "# [ 사용 방법 ]\n",
    "# 1. `file_name` 변수에 읽어올 CSV 파일의 이름을 정확히 입력합니다.\n",
    "# 2. 이 스크립트를 CSV 파일과 동일한 폴더(디렉토리)에 위치시키거나,\n",
    "#    파일 경로를 정확하게 지정합니다.\n",
    "# 3. 스크립트를 실행하면 터미널에 파일 로드 결과와 데이터 정보가 출력됩니다.\n",
    "#\n",
    "# ==================================================================================\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "file_name = \"github_dataset.csv\"\n",
    "\n",
    "\n",
    "print(f\"원본 파일 '{file_name}'을 불러옵니다...\")\n",
    "\n",
    "\n",
    "try:\n",
    "\n",
    "    df = pd.read_csv(file_name, engine=\"python\")\n",
    "\n",
    "\n",
    "    print(\"\\n✅ 원본 파일 로드 성공!\")\n",
    "\n",
    "    print(\"데이터프레임 정보:\")\n",
    "\n",
    "    df.info()\n",
    "\n",
    "\n",
    "    print(f\"\\n전체 행 개수: {len(df)}\")\n",
    "\n",
    "    print(\"\\n데이터 미리보기:\")\n",
    "\n",
    "    print(df.tail())\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\n",
    "\n",
    "        f\"오류: '{file_name}' 파일을 찾을 수 없습니다. 파일이 코드와 같은 폴더에 있는지 확인해주세요.\"\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "\n",
    "    print(f\"파일을 읽는 중 오류가 발생했습니다: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5ea8aafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                         2231\n",
       "transcript    저는 학교를 졸업한 지 오래되어서 어~ 기억이 쪼금 먼 기리 멀기는 하지만 어~ 저...\n",
       "confidence                                                  NaN\n",
       "label                                                         0\n",
       "Name: 2231, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2231]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f43ad85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일을 다음 경로에서 찾습니다: c:\\Users\\user\\Downloads\\woogawooga\\woogawooga_project\\dataset_create\\github_dataset.csv\n",
      "\n",
      "✅ 'github_dataset.csv' 파일을 성공적으로 불러왔습니다. (총 2927개 행)\n",
      "\n",
      " 작업이 완료되었습니다.\n",
      "피싱 데이터가 'phishing_data.csv' 파일로 저장되었습니다. (총 695개 행)\n",
      "일반 데이터가 'normal_data.csv' 파일로 저장되었습니다. (총 2232개 행)\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================================\n",
    "# Pandas를 이용한 데이터셋 분리 및 전처리 스크립트\n",
    "# ==================================================================================\n",
    "#\n",
    "# [ 주요 기능 ]\n",
    "# 1. 데이터 분리: 원본 CSV 파일('github_dataset.csv')을 불러온 후, 미리 지정된\n",
    "#    행 인덱스(PHISHING_ROW_INDICES)를 기준으로 '피싱(phishing)' 데이터와\n",
    "#    '일반(normal)' 데이터를 두 개의 데이터프레임으로 분리합니다.\n",
    "#\n",
    "# 2. 열 이름 변경 및 정제:\n",
    "#    - '피싱' 데이터는 'file_name', 'phishing_type', 'speaker', 'text' 열을 선택하고,\n",
    "#      그에 맞게 열 이름을 표준화합니다.\n",
    "#    - '일반' 데이터는 'file_name', 'text' 열만 선택하고, 동일하게 열 이름을 맞춥니다.\n",
    "#\n",
    "# 3. 파일 저장: 전처리가 완료된 두 개의 데이터프레임을 각각 'phishing_data.csv'와\n",
    "#    'normal_data.csv'라는 새로운 파일로 저장합니다.\n",
    "#    - `encoding=\"utf-8-sig\"` 옵션을 사용하여 한글 깨짐 문제를 방지합니다.\n",
    "#\n",
    "# 4. 강력한 오류 처리: 파일이 없거나, 지정한 행 번호가 범위를 벗어나거나,\n",
    "#    특정 열 이름이 존재하지 않는 등 다양한 예외 상황에 대한 오류 메시지를 출력하여\n",
    "#    문제 해결을 돕습니다.\n",
    "#\n",
    "# [ 사용 방법 ]\n",
    "# 1. `FILE_TO_READ` 변수에 원본 CSV 파일명을 입력합니다.\n",
    "# 2. `PHISHING_ROW_INDICES` 리스트에 피싱 데이터에 해당하는 행 번호 범위를 지정합니다.\n",
    "# 3. 스크립트를 실행하면, 동일한 폴더에 결과물인 csv 파일 2개가 생성됩니다.\n",
    "#\n",
    "# ==================================================================================\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "FILE_TO_READ = \"github_dataset.csv\"\n",
    "\n",
    "\n",
    "PHISHING_ROW_INDICES = list(range(2232, 2927))\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "\n",
    "\n",
    "    current_dir = os.getcwd()\n",
    "\n",
    "\n",
    "    file_path = os.path.join(current_dir, FILE_TO_READ)\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"파일을 다음 경로에서 찾습니다: {file_path}\")\n",
    "\n",
    "\n",
    "\n",
    "    df = pd.read_csv(file_path, engine='python')\n",
    "\n",
    "\n",
    "    print(f\"\\n✅ '{FILE_TO_READ}' 파일을 성공적으로 불러왔습니다. (총 {len(df)}개 행)\")\n",
    "\n",
    "\n",
    "\n",
    "    phishing_df = df.iloc[PHISHING_ROW_INDICES].copy()\n",
    "\n",
    "\n",
    "    normal_df = df[~df.index.isin(PHISHING_ROW_INDICES)].copy()\n",
    "\n",
    "\n",
    "\n",
    "    phishing_final_df = phishing_df.rename(columns={\n",
    "\n",
    "\n",
    "        'id': 'file_name',\n",
    "\n",
    "\n",
    "        'confidence': 'phishing_type',\n",
    "\n",
    "\n",
    "        'label': 'speaker',\n",
    "\n",
    "\n",
    "        'transcript': 'text'\n",
    "\n",
    "\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "    phishing_final_df = phishing_final_df[['file_name', 'phishing_type', 'speaker', 'text']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    normal_final_df = normal_df.rename(columns={\n",
    "\n",
    "\n",
    "        'id': 'file_name',\n",
    "\n",
    "\n",
    "        'transcript': 'text'\n",
    "\n",
    "\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "    normal_final_df = normal_final_df[['file_name', 'text']]\n",
    "\n",
    "\n",
    "\n",
    "    phishing_final_df.to_csv(\"phishing_data.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "\n",
    "    normal_final_df.to_csv(\"normal_data.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\n 작업이 완료되었습니다.\")\n",
    "    print(\n",
    "\n",
    "\n",
    "        f\"피싱 데이터가 'phishing_data.csv' 파일로 저장되었습니다. (총 {len(phishing_final_df)}개 행)\"\n",
    "    )\n",
    "    print(\n",
    "\n",
    "\n",
    "        f\"일반 데이터가 'normal_data.csv' 파일로 저장되었습니다. (총 {len(normal_final_df)}개 행)\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "\n",
    "\n",
    "    print(f\"\\n 오류: '{file_path}' 경로에 파일이 없습니다.\")\n",
    "\n",
    "\n",
    "except IndexError:\n",
    "    print(\n",
    "\n",
    "\n",
    "        f\"\\n 오류: 'PHISHING_ROW_INDICES'에 지정된 행 번호가 실제 파일의 전체 행 수를 벗어났습니다.\"\n",
    "    )\n",
    "\n",
    "\n",
    "except KeyError as e:\n",
    "\n",
    "\n",
    "    print(f\"\\n 오류: '{e}' 컬럼을 찾을 수 없습니다. 원본 파일에 해당 컬럼이 있는지 확인해주세요.\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "\n",
    "\n",
    "    print(f\"오류가 발생했습니다: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb467180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 작업 완료! 문장 분리 결과 (상위 10개):\n",
      "   file_name                                               text\n",
      "0          0                           저는 여행 다니는 것을 굉장히 좋아하는데요.\n",
      "0          0  그래가지고 스페인이나 뭐 영국 유럽 아니면 국내에서도 뭐 강릉이나 전주 같은 데를 ...\n",
      "0          0        저 여행 다니는 거 되게 좋아해서 대학교 내내 여행을 엄청 많이 다녔었는데요.\n",
      "0          0  제가 고등학교 때는 여행에 대해 흥미가 없었는데 그게 좀 아버지가 짠대로 패키지처럼...\n",
      "0          0  그래서 대학교 간 이후로는 해외여행을 되게 많이 갔었는데 그중에서 제일 기 좋았던 ...\n",
      "0          0                어~ 혹시 포르투갈이나 스페인 유럽 쪽 다녀오신 적 있으신가요?\n",
      "0          0                                              어~ 네.\n",
      "0          0                        저도 우연히 스페인과 포르투갈을 다녀왔었었습니다.\n",
      "0          0  어~ 저는 스페인 중에서도 마드리드에 근교에 있었던 톨레도라는 지역이 굉장히 좋았는데요.\n",
      "0          0  그 톨레도에서 특히 기억에 남았던 거는 거기에 대성당이 있는데 그 성당이 엄청 화려...\n",
      "\n",
      "'sentences_data.csv' 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================================\n",
    "# Pandas와 정규표현식을 이용한 텍스트 데이터 문장 단위 분리 스크립트\n",
    "# ==================================================================================\n",
    "#\n",
    "# [ 주요 기능 ]\n",
    "# 1. 문장 분리: 'text' 열에 있는 긴 텍스트를 마침표(.), 물음표(?), 느낌표(!)를 기준으로\n",
    "#    잘라내어 여러 개의 문장으로 만듭니다.\n",
    "#    - 정규표현식(re.split)을 사용하여 분리하며, 각 문장이 원래의 구두점을 유지하도록 처리합니다.\n",
    "#\n",
    "# 2. 데이터 재구성 (Explode): 분리된 문장 리스트를 'explode' 함수를 사용해 각각의 행으로\n",
    "#    만들어, '하나의 행 = 하나의 문장' 구조로 데이터를 변환합니다.\n",
    "#\n",
    "# 3. 데이터 정제:\n",
    "#    - 원본 'text' 열을 삭제하고, 문장이 담긴 새 열의 이름을 'text'로 변경합니다.\n",
    "#    - 분리 과정에서 생길 수 있는 빈 행이나 공백만 있는 행을 제거합니다.\n",
    "#\n",
    "# 4. 파일 저장: 최종적으로 정제된 데이터를 'sentences_data.csv' 파일로 저장하여,\n",
    "#    문장 단위 분석을 위한 데이터셋을 생성합니다.\n",
    "#\n",
    "# [ 사용 방법 ]\n",
    "# 1. 이 스크립트를 'normal_data.csv' 파일과 같은 폴더에 위치시킵니다.\n",
    "# 2. 스크립트를 실행하면, 문장 분리 작업이 완료되고 결과 미리보기와 함께\n",
    "#    'sentences_data.csv' 파일이 생성됩니다.\n",
    "#\n",
    "# ==================================================================================\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "try:\n",
    "\n",
    "    df = pd.read_csv(\"normal_data.csv\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "\n",
    "    print(\"오류: 'normal_data.csv' 파일을 찾을 수 없습니다.\")\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "\n",
    "if not df.empty:\n",
    "\n",
    "    df[\"sentences\"] = df[\"text\"].apply(\n",
    "\n",
    "        lambda x: [\n",
    "\n",
    "            s.strip() + d\n",
    "\n",
    "            for s, d in zip(\n",
    "\n",
    "                re.split(r\"([.?!])\", str(x))[:-1:2], re.split(r\"([.?!])\", str(x))[1::2]\n",
    "            )\n",
    "\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    df_exploded = df.explode(\"sentences\")\n",
    "\n",
    "    df_final = df_exploded.drop(columns=[\"text\"]).rename(columns={\"sentences\": \"text\"})\n",
    "\n",
    "    df_final = df_final[[\"file_name\", \"text\"]]\n",
    "\n",
    "    df_final = df_final.dropna(subset=[\"text\"])\n",
    "\n",
    "    df_final = df_final[df_final[\"text\"].str.strip() != \"\"]\n",
    "\n",
    "\n",
    "    print(\"✅ 작업 완료! 문장 분리 결과 (상위 10개):\")\n",
    "\n",
    "    print(df_final.head(10))\n",
    "\n",
    "\n",
    "    df_final.to_csv('sentences_data.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(\"\\n'sentences_data.csv' 파일로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d6b946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "woogawooga-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
