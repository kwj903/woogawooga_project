{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10a554f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "표제어 기반 형태소 분석 완료: '형태소분석_표제어_결과.csv' 저장됨\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from kiwipiepy import Kiwi\n",
    "\n",
    "# 1. CSV 불러오기\n",
    "phishing_df = pd.read_csv(\"C:/Users/user/Downloads/0708/woogawooga_project/dataset_create/Chaeyeon/피싱데이터에서llm테스트뺀것.csv\")\n",
    "normal_df = pd.read_csv(\"C:/Users/user/Downloads/0708/woogawooga_project/dataset_create/Chaeyeon/일반통화_남은셋.csv\")\n",
    "\n",
    "# 2. 라벨 추가 및 병합\n",
    "phishing_df['label'] = '1'\n",
    "normal_df['label'] = '0'\n",
    "df_all = pd.concat([phishing_df, normal_df], ignore_index=True)\n",
    "\n",
    "# 3. Kiwi 초기화\n",
    "kiwi = Kiwi()\n",
    "\n",
    "# 4. 추출할 품사 (표제어 기반)\n",
    "target_pos = ['NNG', 'NNP', 'VV', 'VA']  # 명사, 동사, 형용사\n",
    "\n",
    "# 5. 표제어 추출 함수\n",
    "def extract_lemmas(text):\n",
    "    results = kiwi.analyze(text)\n",
    "    lemmas = []\n",
    "    for morph in results[0][0]:  # 첫 번째 해석 결과만 사용\n",
    "        if morph.tag in target_pos:\n",
    "            lemmas.append(morph.lemma)  # 표제어\n",
    "    return ' '.join(lemmas)\n",
    "\n",
    "# 6. tokenized_text 컬럼 생성 (표제어 기반)\n",
    "df_all['tokenized_text'] = df_all['text'].astype(str).apply(extract_lemmas)\n",
    "\n",
    "# 7. 저장\n",
    "df_all.to_csv(\"형태소분석_표제어_결과.csv\", index=False, encoding='utf-8-sig')\n",
    "print(\"표제어 기반 형태소 분석 완료: '형태소분석_표제어_결과.csv' 저장됨\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa157d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        장판 문의 드리다 전화 드리다 경주 교도소 총무과 하다 되다 재소자 방 보수 공사 ...\n",
       "1                             교도관 보호 조끼 있다 거래처 있다 원 단가 올리다\n",
       "2                                  사장 주문 넣다 되다 사장 가다 결제 하다\n",
       "3                  서울지검 수사관 다르다 앞 명의 도용 사건 관련 확인 차다 연락 드리다\n",
       "4                         주위 잡음 섞이다 목소리 섞이다 대화 하다 없다 공간 전화\n",
       "                               ...                        \n",
       "65892    감사 좋다 하루 되다 문의 사항 없다 기다리다 감사 그러다 기다리다 기다리다 죄송하...\n",
       "65893    감사 선생 맞다 아이 아이 시간 없다 취소 사유 말씀 부탁 드리다 확인 감사 기다리...\n",
       "65894                 교재 환불 관련 문의 드리다 확인 감사 환불 사유 되다 감사 감사\n",
       "65895    감사 감사 기간 지나다 지나다 보내다 맞다 환불 신청 하다 환불 등록 되다 같다 등...\n",
       "65896    회원 그러다 카드 취소 진행 되다 전체 취소 가능 가능 결제 교재 캐시 넣다 괜찮다...\n",
       "Name: tokenized_text, Length: 65897, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['tokenized_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54ba2cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1260\\2427227206.py:5: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"C:/Users/user/Downloads/0708/woogawooga_project/dataset_create/Chaeyeon/형태소분석_표제어_결과.csv\")\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1260\\2427227206.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered[\"tokenized_text\"] = df_filtered[\"tokenized_text\"].astype(str).fillna(\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대화 단위 TF-IDF 계산 완료: '대화단위_TFIDF_결과.csv' 저장됨\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 1. 형태소+표제어 처리된 CSV 불러오기\n",
    "df = pd.read_csv(\"C:/Users/user/Downloads/0708/woogawooga_project/dataset_create/Chaeyeon/형태소분석_표제어_결과.csv\")\n",
    "\n",
    "# 2. file_name 필터링 (phishing_1281 ~ phishing_2046)\n",
    "def is_in_range(name):\n",
    "    if name.startswith(\"phishing_\"):\n",
    "        try:\n",
    "            num = int(name.split(\"_\")[1])\n",
    "            return 1281 <= num <= 2046\n",
    "        except:\n",
    "            return False\n",
    "    return False\n",
    "\n",
    "df_filtered = df[df[\"file_name\"].apply(is_in_range)]\n",
    "\n",
    "# 3. tokenized_text 컬럼 NaN 제거 및 문자열 변환\n",
    "df_filtered[\"tokenized_text\"] = df_filtered[\"tokenized_text\"].astype(str).fillna(\"\")\n",
    "\n",
    "# 4. file_name 기준으로 대화 단위 결합\n",
    "grouped = df_filtered.groupby(\"file_name\")[\"tokenized_text\"].apply(lambda x: ' '.join(str(i) for i in x if pd.notnull(i))).reset_index()\n",
    "\n",
    "# (선택) 라벨도 붙이기\n",
    "labels = df_filtered[['file_name', 'label']].drop_duplicates()\n",
    "grouped = pd.merge(grouped, labels, on='file_name')\n",
    "\n",
    "# 5. TF-IDF 계산 (대화 단위)\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(grouped['tokenized_text'])\n",
    "\n",
    "# 6. 결과 DataFrame으로 변환\n",
    "words = vectorizer.get_feature_names_out()\n",
    "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=words)\n",
    "df_tfidf['file_name'] = grouped['file_name']\n",
    "df_tfidf['label'] = grouped['label']\n",
    "\n",
    "# 7. CSV 저장\n",
    "df_tfidf.to_csv(\"대화단위_TFIDF_결과.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"대화 단위 TF-IDF 계산 완료: '대화단위_TFIDF_결과.csv' 저장됨\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e8380c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "woogawooga-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
