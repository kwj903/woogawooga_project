{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14901131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C:/Users/user/Desktop/보이스피싱/woogawooga_project/dataset/normal_비율맞춘_학습데이터셋.csv')\n",
    "df.rename(columns={'file_name': 'file_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f32b37b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"normal_비율맞춘_학습데이터셋2.csv\", index=False, encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04fb87ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 저장: phishing_keyword_pipeline2\\phish_dialogue.csv\n",
      "CSV 저장: phishing_keyword_pipeline2\\normal_dialogue.csv\n",
      "CSV 저장: phishing_keyword_pipeline2\\phish_tokenized.csv\n",
      "CSV 저장: phishing_keyword_pipeline2\\normal_tokenized.csv\n",
      "JSON 저장: phishing_keyword_pipeline2\\risk_dict2.json\n",
      "JSON 저장: phishing_keyword_pipeline2\\top_keywords_log2.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from kiwipiepy import Kiwi\n",
    "\n",
    "# 1. 경로 설정 및 저장 함수\n",
    "save_dir = \"phishing_keyword_pipeline2\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "def save_csv(df, name):\n",
    "    path = os.path.join(save_dir, name)\n",
    "    df.to_csv(path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"CSV 저장: {path}\")\n",
    "\n",
    "def save_json(obj, name):\n",
    "    path = os.path.join(save_dir, name)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"JSON 저장: {path}\")\n",
    "\n",
    "# 2. 데이터 불러오기\n",
    "df_phish = pd.read_csv(\"C:/Users/user/Desktop/보이스피싱/woogawooga_project/dataset_create/Chaeyeon/phishing_total_0716_1345.csv\")\n",
    "df_normal = pd.read_csv(\"C:/Users/user/Desktop/보이스피싱/woogawooga_project/dataset_create/Chaeyeon/normal_비율맞춘_학습데이터셋2.csv\")\n",
    "\n",
    "# 3. 대화 단위로 묶기\n",
    "phish_dialogue = df_phish.groupby(\"file_id\").agg({\n",
    "    \"text\": lambda x: \" \".join(x),\n",
    "    \"phishing_type\": \"first\"\n",
    "}).reset_index()\n",
    "\n",
    "normal_dialogue = df_normal.groupby(\"file_id\")[\"text\"].apply(lambda x: \" \".join(x)).reset_index()\n",
    "\n",
    "save_csv(phish_dialogue, \"phish_dialogue.csv\")\n",
    "save_csv(normal_dialogue, \"normal_dialogue.csv\")\n",
    "\n",
    "# 4. Kiwi 형태소 분석기 + NNP 제거\n",
    "kiwi = Kiwi()\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = kiwi.tokenize(str(text))\n",
    "    return ' '.join([\n",
    "        token.lemma for token in tokens\n",
    "        if (token.tag.startswith(\"N\") or token.tag.startswith(\"V\") or token.tag.startswith(\"VA\"))\n",
    "        and not token.tag.startswith(\"NNP\")  # 고유명사 제거\n",
    "    ])\n",
    "\n",
    "phish_dialogue[\"tokenized_text\"] = phish_dialogue[\"text\"].apply(tokenize)\n",
    "normal_dialogue[\"tokenized_text\"] = normal_dialogue[\"text\"].apply(tokenize)\n",
    "\n",
    "save_csv(phish_dialogue, \"phish_tokenized.csv\")\n",
    "save_csv(normal_dialogue, \"normal_tokenized.csv\")\n",
    "\n",
    "# 5. TF-IDF 기반 위험도 계산 (보이스피싱 vs 일반대화)\n",
    "all_docs = list(phish_dialogue[\"tokenized_text\"]) + list(normal_dialogue[\"tokenized_text\"])\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "tfidf_matrix = vectorizer.fit_transform(all_docs)\n",
    "words = vectorizer.get_feature_names_out()\n",
    "\n",
    "n_phish = len(phish_dialogue)\n",
    "n_normal = len(normal_dialogue)\n",
    "phish_avg = tfidf_matrix[:n_phish].mean(axis=0).A1\n",
    "normal_avg = tfidf_matrix[n_phish:].mean(axis=0).A1\n",
    "\n",
    "epsilon = 1e-6\n",
    "risk_dict = {word: phish_avg[i] / (normal_avg[i] + epsilon) for i, word in enumerate(words)}\n",
    "save_json(risk_dict, \"risk_dict2.json\")\n",
    "\n",
    "# 6. 위험도 × log(등장빈도) 기반 유형별 키워드 추출\n",
    "top_keywords_log = {}\n",
    "\n",
    "for ptype, group in phish_dialogue.groupby(\"phishing_type\"):\n",
    "    tokens = ' '.join(group[\"tokenized_text\"]).split()\n",
    "    counts = Counter(tokens)\n",
    "\n",
    "    keyword_scores = {\n",
    "        word: risk_dict.get(word, 0) * np.log1p(counts[word])\n",
    "        for word in counts if word in risk_dict\n",
    "    }\n",
    "\n",
    "    top50 = sorted(keyword_scores.items(), key=lambda x: x[1], reverse=True)[:50]\n",
    "    top_keywords_log[ptype] = dict(top50)\n",
    "\n",
    "save_json(top_keywords_log, \"top_keywords_log2.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa25ad2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.csv 저장 완료!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# 1. 데이터 로드\n",
    "phish_df = pd.read_csv(\"phishing_keyword_pipeline2/phish_tokenized.csv\")\n",
    "normal_df = pd.read_csv(\"phishing_keyword_pipeline2/normal_tokenized.csv\")\n",
    "\n",
    "phish_df[\"label\"] = 1\n",
    "normal_df[\"label\"] = 0\n",
    "\n",
    "total_df = pd.concat([phish_df, normal_df], ignore_index=True)\n",
    "\n",
    "# 2. 키워드 로드\n",
    "with open(\"phishing_keyword_pipeline2/top_keywords_log2.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    keyword_dict = json.load(f)\n",
    "\n",
    "# 3. 전체 키워드 목록 통합\n",
    "all_keywords = set()\n",
    "for keyword_list in keyword_dict.values():\n",
    "    all_keywords.update(keyword_list.keys())\n",
    "\n",
    "# 정렬해서 고정된 순서로 사용\n",
    "all_keywords = sorted(all_keywords)\n",
    "\n",
    "# 4. 등장 횟수 기반 feature 생성\n",
    "def keyword_count_vector(text, keyword_set):\n",
    "    tokens = text.split()\n",
    "    counts = Counter(tokens)\n",
    "    return [counts.get(word, 0) for word in keyword_set]\n",
    "\n",
    "# 5. X, y 생성\n",
    "X = total_df[\"tokenized_text\"].apply(lambda x: keyword_count_vector(x, all_keywords))\n",
    "X_df = pd.DataFrame(X.tolist(), columns=[f\"kw_{kw}\" for kw in all_keywords])\n",
    "X_df[\"label\"] = total_df[\"label\"]\n",
    "\n",
    "# 6. 저장\n",
    "X_df.to_csv(\"phishing_keyword_pipeline2/X_train.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"X_train.csv 저장 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a95ca561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF 변환 완료 및 저장됨!\n",
      "TF-IDF 행렬 shape: (12386, 142)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import scipy\n",
    "\n",
    "# 1. 데이터 불러오기\n",
    "df = pd.read_csv(\"phishing_keyword_pipeline2/X_train.csv\")\n",
    "\n",
    "# 2. 레이블 분리\n",
    "y = df[\"label\"]\n",
    "X_counts = df.drop(columns=[\"label\"])\n",
    "\n",
    "# 3. TF-IDF 가중치 적용\n",
    "transformer = TfidfTransformer()\n",
    "X_tfidf = transformer.fit_transform(X_counts)\n",
    "\n",
    "# 4. 저장 (압축 희소행렬 포맷으로 저장)\n",
    "scipy.sparse.save_npz(\"phishing_keyword_pipeline2/X_train_tfidf.npz\", X_tfidf)\n",
    "y.to_csv(\"phishing_keyword_pipeline2/y_train.csv\", index=False)\n",
    "\n",
    "print(\"TF-IDF 변환 완료 및 저장됨!\")\n",
    "print(f\"TF-IDF 행렬 shape: {X_tfidf.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d2e7f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 성능 평가 결과\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9010    0.9325    0.9165      1200\n",
      "           1     0.9345    0.9038    0.9189      1278\n",
      "\n",
      "    accuracy                         0.9177      2478\n",
      "   macro avg     0.9177    0.9181    0.9177      2478\n",
      "weighted avg     0.9182    0.9177    0.9177      2478\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1119   81]\n",
      " [ 123 1155]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['phishing_keyword_pipeline2/boryunull.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 데이터 불러오기\n",
    "X = scipy.sparse.load_npz(\"phishing_keyword_pipeline2/X_train_tfidf.npz\")\n",
    "y = pd.read_csv(\"phishing_keyword_pipeline2/y_train.csv\").values.ravel()\n",
    "\n",
    "# 학습/검증 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 로지스틱 회귀 모델 학습\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 예측 및 평가\n",
    "y_pred = model.predict(X_val)\n",
    "print(\"모델 성능 평가 결과\")\n",
    "print(classification_report(y_val, y_pred, digits=4))\n",
    "\n",
    "# 5. 혼동 행렬 (추가 분석용)\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# 6. 모델 저장 (선택)\n",
    "import joblib\n",
    "joblib.dump(model, \"phishing_keyword_pipeline2/boryunull.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b811dc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 예측 결과 분포 (0: 일반, 1: 피싱, 2: 보류):\n",
      "pred\n",
      "0    1139\n",
      "1    1114\n",
      "2     225\n",
      "Name: count, dtype: int64\n",
      "\n",
      " 보류 제외하고 정확도 평가 (0과 1만):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9254    0.9582    0.9415      1100\n",
      "           1     0.9587    0.9263    0.9422      1153\n",
      "\n",
      "    accuracy                         0.9419      2253\n",
      "   macro avg     0.9420    0.9422    0.9419      2253\n",
      "weighted avg     0.9424    0.9419    0.9419      2253\n",
      "\n",
      "\n",
      " 전체 2478개 중 보류된 데이터: 225개 (9.1%)\n",
      "모델 저장 완료: model_logistic_v1.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 1. 데이터 불러오기\n",
    "X = scipy.sparse.load_npz(\"phishing_keyword_pipeline2/X_train_tfidf.npz\")\n",
    "y = pd.read_csv(\"phishing_keyword_pipeline2/y_train.csv\").values.ravel()\n",
    "\n",
    "# 2. 학습/검증 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 3. 로지스틱 모델 학습\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4. 확률 기반 예측\n",
    "y_prob = model.predict_proba(X_val)[:, 1]  # 클래스 1(피싱) 확률만 가져오기\n",
    "\n",
    "# 5. 보류 구간 처리\n",
    "def classify(prob):\n",
    "    if prob < 0.3:\n",
    "        return 0  # 일반\n",
    "    elif prob > 0.7:\n",
    "        return 1  # 피싱\n",
    "    else:\n",
    "        return 2  # 보류\n",
    "\n",
    "y_pred_custom = [classify(p) for p in y_prob]\n",
    "\n",
    "# 6. 평가 출력\n",
    "results_df = pd.DataFrame({\n",
    "    \"true\": y_val,\n",
    "    \"prob\": y_prob,\n",
    "    \"pred\": y_pred_custom\n",
    "})\n",
    "\n",
    "# 7. 각 클래스별 개수 확인\n",
    "print(\" 예측 결과 분포 (0: 일반, 1: 피싱, 2: 보류):\")\n",
    "print(results_df[\"pred\"].value_counts())\n",
    "\n",
    "# 8. 혼동행렬 (보류 제외한 평가)\n",
    "print(\"\\n 보류 제외하고 정확도 평가 (0과 1만):\")\n",
    "mask = results_df[\"pred\"] != 2\n",
    "print(classification_report(results_df[\"true\"][mask], results_df[\"pred\"][mask], digits=4))\n",
    "\n",
    "# 9. 보류된 데이터 수\n",
    "n_total = len(results_df)\n",
    "n_hold = (results_df[\"pred\"] == 2).sum()\n",
    "print(f\"\\n 전체 {n_total}개 중 보류된 데이터: {n_hold}개 ({n_hold / n_total:.1%})\")\n",
    "\n",
    "# 저장\n",
    "joblib.dump(model, \"phishing_keyword_pipeline2/model_logistic_v1.pkl\")\n",
    "print(\"모델 저장 완료: model_logistic_v1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f994353d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결과 저장 완료: 보류구간_성능비교.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# 1. 파일 경로\n",
    "X = scipy.sparse.load_npz(\"phishing_keyword_pipeline2/X_train_tfidf.npz\")\n",
    "y = pd.read_csv(\"phishing_keyword_pipeline2/y_train.csv\").values.ravel()\n",
    "\n",
    "# 2. 데이터 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 3. 로지스틱 모델 학습\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "y_prob = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# 4. 다양한 보류 구간 테스트\n",
    "thresholds = [(round(i, 2), round(j, 2)) for i in np.arange(0.1, 0.5, 0.05)\n",
    "                                            for j in np.arange(0.6, 0.91, 0.05) if i < j]\n",
    "\n",
    "results = []\n",
    "\n",
    "for low, high in thresholds:\n",
    "    def classify(p):\n",
    "        if p < low:\n",
    "            return 0\n",
    "        elif p > high:\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "\n",
    "    y_pred = np.array([classify(p) for p in y_prob])\n",
    "    mask = y_pred != 2\n",
    "\n",
    "    if np.sum(mask) == 0:\n",
    "        continue\n",
    "\n",
    "    prec = precision_score(y_val[mask], y_pred[mask], zero_division=0)\n",
    "    rec = recall_score(y_val[mask], y_pred[mask])\n",
    "    f1 = f1_score(y_val[mask], y_pred[mask])\n",
    "    hold_rate = 1 - np.mean(mask)\n",
    "\n",
    "    results.append({\n",
    "        \"보류_하한\": low,\n",
    "        \"보류_상한\": high,\n",
    "        \"precision\": round(prec, 4),\n",
    "        \"recall\": round(rec, 4),\n",
    "        \"f1_score\": round(f1, 4),\n",
    "        \"보류비율(%)\": round(hold_rate * 100, 1)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"f1_score\", ascending=False)\n",
    "results_df.to_csv(\"phishing_keyword_pipeline2/보류구간_성능비교.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"결과 저장 완료: 보류구간_성능비교.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19a48367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 예측 결과 분포 (0: 일반, 1: 피싱, 2: 보류):\n",
      "pred\n",
      "0    1096\n",
      "1     955\n",
      "2     427\n",
      "Name: count, dtype: int64\n",
      "\n",
      " 보류 제외하고 정확도 평가 (0과 1만):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9343    0.9808    0.9570      1044\n",
      "           1     0.9791    0.9285    0.9531      1007\n",
      "\n",
      "    accuracy                         0.9551      2051\n",
      "   macro avg     0.9567    0.9547    0.9551      2051\n",
      "weighted avg     0.9563    0.9551    0.9551      2051\n",
      "\n",
      "\n",
      " 전체 2478개 중 보류된 데이터: 427개 (17.2%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 1. 데이터 불러오기\n",
    "X = scipy.sparse.load_npz(\"phishing_keyword_pipeline2/X_train_tfidf.npz\")\n",
    "y = pd.read_csv(\"phishing_keyword_pipeline2/y_train.csv\").values.ravel()\n",
    "\n",
    "# 2. 학습/검증 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 3. 로지스틱 모델 학습\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4. 확률 기반 예측\n",
    "y_prob = model.predict_proba(X_val)[:, 1]  # 클래스 1(피싱) 확률만 가져오기\n",
    "\n",
    "# 5. 보류 구간 처리\n",
    "def classify(prob):\n",
    "    if prob < 0.15:\n",
    "        return 0  # 일반\n",
    "    elif prob > 0.85:\n",
    "        return 1  # 피싱\n",
    "    else:\n",
    "        return 2  # 보류\n",
    "\n",
    "y_pred_custom = [classify(p) for p in y_prob]\n",
    "\n",
    "# 6. 평가 출력\n",
    "results_df = pd.DataFrame({\n",
    "    \"true\": y_val,\n",
    "    \"prob\": y_prob,\n",
    "    \"pred\": y_pred_custom\n",
    "})\n",
    "\n",
    "# 7. 각 클래스별 개수 확인\n",
    "print(\" 예측 결과 분포 (0: 일반, 1: 피싱, 2: 보류):\")\n",
    "print(results_df[\"pred\"].value_counts())\n",
    "\n",
    "# 8. 혼동행렬 (보류 제외한 평가)\n",
    "print(\"\\n 보류 제외하고 정확도 평가 (0과 1만):\")\n",
    "mask = results_df[\"pred\"] != 2\n",
    "print(classification_report(results_df[\"true\"][mask], results_df[\"pred\"][mask], digits=4))\n",
    "\n",
    "# 9. 보류된 데이터 수\n",
    "n_total = len(results_df)\n",
    "n_hold = (results_df[\"pred\"] == 2).sum()\n",
    "print(f\"\\n 전체 {n_total}개 중 보류된 데이터: {n_hold}개 ({n_hold / n_total:.1%})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32171a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest 결과 (보류 제외)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9335    0.9924    0.9620      1046\n",
      "           1     0.9923    0.9332    0.9618      1107\n",
      "\n",
      "    accuracy                         0.9619      2153\n",
      "   macro avg     0.9629    0.9628    0.9619      2153\n",
      "weighted avg     0.9637    0.9619    0.9619      2153\n",
      "\n",
      "보류 비율: 13.1%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['phishing_keyword_pipeline2/model_randomforest_v1.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1. 데이터 로드\n",
    "X = scipy.sparse.load_npz(\"phishing_keyword_pipeline2/X_train_tfidf.npz\")\n",
    "y = pd.read_csv(\"phishing_keyword_pipeline2/y_train.csv\").values.ravel()\n",
    "\n",
    "# 2. train/test 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 3. 랜덤 포레스트 모델 학습\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 4. 예측 확률\n",
    "y_prob = rf_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# 5. 보류 구간 기준 예측 (예: 0.10 ~ 0.75)\n",
    "def classify(p, low=0.10, high=0.9):\n",
    "    if p < low:\n",
    "        return 0\n",
    "    elif p > high:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "y_pred_custom = np.array([classify(p) for p in y_prob])\n",
    "\n",
    "# 6. 평가 (보류 제외)\n",
    "results_df = pd.DataFrame({\n",
    "    \"true\": y_val,\n",
    "    \"prob\": y_prob,\n",
    "    \"pred\": y_pred_custom\n",
    "})\n",
    "\n",
    "mask = results_df[\"pred\"] != 2\n",
    "print(\"Random Forest 결과 (보류 제외)\")\n",
    "print(classification_report(results_df[\"true\"][mask], results_df[\"pred\"][mask], digits=4))\n",
    "print(f\"보류 비율: {(results_df['pred'] == 2).mean() * 100:.1f}%\")\n",
    "\n",
    "# 7. 모델 저장 (선택)\n",
    "import joblib\n",
    "joblib.dump(rf_model, \"phishing_keyword_pipeline2/model_randomforest_v1.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d3140be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤 포레스트 보류구간 실험 완료!\n",
      "저장됨: RandomForest_보류구간_성능비교.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# 1. 데이터 로딩\n",
    "X = scipy.sparse.load_npz(\"phishing_keyword_pipeline2/X_train_tfidf.npz\")\n",
    "y = pd.read_csv(\"phishing_keyword_pipeline2/y_train.csv\").values.ravel()\n",
    "\n",
    "# 2. 데이터 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 3. 랜덤 포레스트 모델 학습\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 4. 예측 확률\n",
    "y_prob = rf_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# 5. 다양한 보류 구간 실험\n",
    "thresholds = [(round(i, 2), round(j, 2)) for i in np.arange(0.1, 0.5, 0.05)\n",
    "                                            for j in np.arange(0.6, 0.91, 0.05) if i < j]\n",
    "\n",
    "results = []\n",
    "\n",
    "for low, high in thresholds:\n",
    "    def classify(p):\n",
    "        if p < low:\n",
    "            return 0\n",
    "        elif p > high:\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "\n",
    "    y_pred = np.array([classify(p) for p in y_prob])\n",
    "    mask = y_pred != 2\n",
    "\n",
    "    if np.sum(mask) == 0:\n",
    "        continue\n",
    "\n",
    "    prec = precision_score(y_val[mask], y_pred[mask], zero_division=0)\n",
    "    rec = recall_score(y_val[mask], y_pred[mask])\n",
    "    f1 = f1_score(y_val[mask], y_pred[mask])\n",
    "    hold_rate = 1 - np.mean(mask)\n",
    "\n",
    "    results.append({\n",
    "        \"보류_하한\": low,\n",
    "        \"보류_상한\": high,\n",
    "        \"precision\": round(prec, 4),\n",
    "        \"recall\": round(rec, 4),\n",
    "        \"f1_score\": round(f1, 4),\n",
    "        \"보류비율(%)\": round(hold_rate * 100, 1)\n",
    "    })\n",
    "\n",
    "# 6. 저장\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"f1_score\", ascending=False)\n",
    "results_df.to_csv(\"phishing_keyword_pipeline2/RandomForest_보류구간_성능비교.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"랜덤 포레스트 보류구간 실험 완료!\")\n",
    "print(\"저장됨: RandomForest_보류구간_성능비교.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad384385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\보이스피싱\\woogawooga_project\\.venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [17:30:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost 결과 (보류 제외):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9324    0.9758    0.9536      1075\n",
      "           1     0.9767    0.9349    0.9553      1167\n",
      "\n",
      "    accuracy                         0.9545      2242\n",
      "   macro avg     0.9546    0.9553    0.9545      2242\n",
      "weighted avg     0.9555    0.9545    0.9545      2242\n",
      "\n",
      "전체 개수: 2478개 중 보류: 236개 (9.5%)\n",
      "모델 저장 완료: model_xgboost_v2.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# 1. 데이터 로딩\n",
    "X = scipy.sparse.load_npz(\"phishing_keyword_pipeline2/X_train_tfidf.npz\")\n",
    "y = pd.read_csv(\"phishing_keyword_pipeline2/y_train.csv\").values.ravel()\n",
    "\n",
    "# 2. train/validation 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 3. XGBoost 모델 학습\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", n_jobs=-1, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 4. 예측 확률\n",
    "y_prob = xgb_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# 5. 보류 구간 분류 (예: 0.10 ~ 0.75)\n",
    "def classify(prob, low=0.10, high=0.75):\n",
    "    if prob < low:\n",
    "        return 0\n",
    "    elif prob > high:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "y_pred = np.array([classify(p) for p in y_prob])\n",
    "\n",
    "# 6. 보류 제외 후 성능 평가\n",
    "mask = y_pred != 2\n",
    "print(\"XGBoost 결과 (보류 제외):\")\n",
    "print(classification_report(y_val[mask], y_pred[mask], digits=4))\n",
    "print(f\"전체 개수: {len(y_pred)}개 중 보류: {np.sum(y_pred == 2)}개 ({np.mean(y_pred == 2) * 100:.1f}%)\")\n",
    "\n",
    "# 7. 모델 저장\n",
    "joblib.dump(xgb_model, \"phishing_keyword_pipeline2/model_xgboost_v2.pkl\")\n",
    "print(\"모델 저장 완료: model_xgboost_v2.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f406301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "woogawooga-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
