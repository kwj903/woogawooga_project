{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a65dd244",
   "metadata": {},
   "source": [
    "# kiwi로 토큰화 및 로지스틱 회귀 모델 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0036d184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일반방법 : 데이터 불균형 고려안함, N그램 안씀, k폴드교차검증 안함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1ea708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from kiwipiepy import Kiwi\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv(\"../../dataset/merged_labeled_data.csv\")\n",
    "\n",
    "# Kiwi 객체 생성\n",
    "kiwi = Kiwi()\n",
    "\n",
    "\n",
    "# 형태소 분석 함수 정의\n",
    "def tokenize_and_filter(text):\n",
    "    result = kiwi.analyze(text)[0][0]  # 첫 번째 결과의 토큰 리스트 사용\n",
    "    tokens = []\n",
    "    for word, pos, _, _ in result:\n",
    "        if pos in {\"NNG\", \"NNP\", \"VV\", \"VA\"}:  # 일반명사, 고유명사, 동사, 형용사\n",
    "            if pos in {\"VV\", \"VA\"}:\n",
    "                word = word + \"다\"  # 동사/형용사는 어간 + '다'로 표제어 처리\n",
    "            tokens.append(word)\n",
    "    return tokens\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e0ef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화된 텍스트 생성\n",
    "df[\"tokens\"] = df[\"text\"].astype(str).apply(tokenize_and_filter)\n",
    "df[\"joined_tokens\"] = df[\"tokens\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df[\"joined_tokens\"])\n",
    "y = df[\"is_phishing\"]\n",
    "\n",
    "# 학습/테스트 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 간단한 분류 모델 (로지스틱 회귀)\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 예측 및 평가\n",
    "y_pred = model.predict(X_test)\n",
    "report = classification_report(y_test, y_pred, output_dict=False)\n",
    "\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc1e977",
   "metadata": {},
   "source": [
    "# k 폴드 교차검증 방식, n그램사용, 데이터 불균형 고려"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a8396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 다시 로드 (중복 방지)\n",
    "df = pd.read_csv(\"../../dataset/merged_labeled_data.csv\")\n",
    "\n",
    "# 형태소 분석기 초기화\n",
    "kiwi = Kiwi()\n",
    "\n",
    "\n",
    "# 형태소 분석 함수 (명사/동사/형용사/고유명사, 표제어 처리 포함)\n",
    "def tokenize_and_filter(text):\n",
    "    result = kiwi.analyze(text)[0][0]\n",
    "    tokens = []\n",
    "    for word, pos, _, _ in result:\n",
    "        if pos in {\"NNG\", \"NNP\", \"VV\", \"VA\"}:\n",
    "            if pos in {\"VV\", \"VA\"}:\n",
    "                word = word + \"다\"\n",
    "            tokens.append(word)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "# 텍스트 전처리\n",
    "df[\"processed_text\"] = df[\"text\"].astype(str).apply(tokenize_and_filter)\n",
    "\n",
    "X = df[\"processed_text\"]\n",
    "y = df[\"is_phishing\"]\n",
    "\n",
    "# 파이프라인 구성: TF-IDF + 로지스틱 회귀 (클래스 불균형 고려, n-gram 적용)\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"tfidf\",\n",
    "            TfidfVectorizer(\n",
    "                sublinear_tf=True,\n",
    "                min_df=5,\n",
    "                max_df=0.9,\n",
    "                ngram_range=(1, 2),  # uni-gram + bi-gram\n",
    "            ),\n",
    "        ),\n",
    "        (\"clf\", LogisticRegression(max_iter=1000, class_weight=\"balanced\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Stratified K-Fold Cross Validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 교차 검증 예측\n",
    "y_pred = cross_val_predict(pipeline, X, y, cv=skf)\n",
    "\n",
    "# 평가 리포트 출력\n",
    "report = classification_report(y, y_pred)\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b208ca1",
   "metadata": {},
   "source": [
    "# 위의 두 방식을 종합하여 비교까지 진행하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c789014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from kiwipiepy import Kiwi\n",
    "\n",
    "# 샘플 데이터 로드 경로 수정 필요 시 여기를 변경하세요\n",
    "data_path = \"../../dataset/merged_labeled_data.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Kiwi 형태소 분석기\n",
    "kiwi = Kiwi()\n",
    "\n",
    "\n",
    "# 토큰화 및 표제어 처리\n",
    "def tokenize_and_filter(text):\n",
    "    result = kiwi.analyze(text)[0][0]\n",
    "    tokens = []\n",
    "    for word, pos, _, _ in result:\n",
    "        if pos in {\"NNG\", \"NNP\", \"VV\", \"VA\"}:\n",
    "            if pos in {\"VV\", \"VA\"}:\n",
    "                word = word + \"다\"\n",
    "            tokens.append(word)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "# 텍스트 전처리\n",
    "df[\"processed_text\"] = df[\"text\"].astype(str).apply(tokenize_and_filter)\n",
    "\n",
    "X = df[\"processed_text\"]\n",
    "y = df[\"is_phishing\"]\n",
    "\n",
    "# ▶ 방식 1: 단순 train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "pipeline_simple = Pipeline(\n",
    "    [\n",
    "        (\"tfidf\", TfidfVectorizer(sublinear_tf=True, min_df=5, max_df=0.9)),\n",
    "        (\"clf\", LogisticRegression(max_iter=1000, class_weight=\"balanced\")),\n",
    "    ]\n",
    ")\n",
    "pipeline_simple.fit(X_train, y_train)\n",
    "y_pred_simple = pipeline_simple.predict(X_test)\n",
    "report_simple = classification_report(y_test, y_pred_simple, output_dict=True)\n",
    "\n",
    "# ▶ 방식 2: K-Fold 교차 검증 + ngram 적용\n",
    "pipeline_kfold = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"tfidf\",\n",
    "            TfidfVectorizer(\n",
    "                sublinear_tf=True, min_df=5, max_df=0.9, ngram_range=(1, 2)\n",
    "            ),\n",
    "        ),\n",
    "        (\"clf\", LogisticRegression(max_iter=1000, class_weight=\"balanced\")),\n",
    "    ]\n",
    ")\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "y_pred_kfold = cross_val_predict(pipeline_kfold, X, y, cv=skf)\n",
    "report_kfold = classification_report(y, y_pred_kfold, output_dict=True)\n",
    "\n",
    "# 결과 비교를 위해 정리\n",
    "comparison = {\"Metric\": [], \"Simple Split\": [], \"K-Fold\": []}\n",
    "\n",
    "for label in [\"0\", \"1\", \"accuracy\", \"macro avg\", \"weighted avg\"]:\n",
    "    if label == \"accuracy\":\n",
    "        comparison[\"Metric\"].append(\"Accuracy\")\n",
    "        comparison[\"Simple Split\"].append(report_simple[\"accuracy\"])\n",
    "        comparison[\"K-Fold\"].append(report_kfold[\"accuracy\"])\n",
    "    else:\n",
    "        for metric in [\"precision\", \"recall\", \"f1-score\"]:\n",
    "            metric_name = (\n",
    "                f\"{label} {metric}\" if label in [\"0\", \"1\"] else f\"{label} {metric}\"\n",
    "            )\n",
    "            comparison[\"Metric\"].append(metric_name)\n",
    "            comparison[\"Simple Split\"].append(report_simple[label][metric])\n",
    "            comparison[\"K-Fold\"].append(report_kfold[label][metric])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "886f5621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Simple Split</th>\n",
       "      <th>K-Fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 precision</td>\n",
       "      <td>0.999161</td>\n",
       "      <td>0.996500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0 recall</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.996500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0 f1-score</td>\n",
       "      <td>0.995819</td>\n",
       "      <td>0.996500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 precision</td>\n",
       "      <td>0.978469</td>\n",
       "      <td>0.989741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 recall</td>\n",
       "      <td>0.997561</td>\n",
       "      <td>0.989741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1 f1-score</td>\n",
       "      <td>0.987923</td>\n",
       "      <td>0.989741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>0.994781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>macro avg precision</td>\n",
       "      <td>0.988815</td>\n",
       "      <td>0.993121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>macro avg recall</td>\n",
       "      <td>0.995030</td>\n",
       "      <td>0.993121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>macro avg f1-score</td>\n",
       "      <td>0.991871</td>\n",
       "      <td>0.993121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>weighted avg precision</td>\n",
       "      <td>0.993892</td>\n",
       "      <td>0.994781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>weighted avg recall</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>0.994781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>weighted avg f1-score</td>\n",
       "      <td>0.993808</td>\n",
       "      <td>0.994781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Metric  Simple Split    K-Fold\n",
       "0              0 precision      0.999161  0.996500\n",
       "1                 0 recall      0.992500  0.996500\n",
       "2               0 f1-score      0.995819  0.996500\n",
       "3              1 precision      0.978469  0.989741\n",
       "4                 1 recall      0.997561  0.989741\n",
       "5               1 f1-score      0.987923  0.989741\n",
       "6                 Accuracy      0.993789  0.994781\n",
       "7      macro avg precision      0.988815  0.993121\n",
       "8         macro avg recall      0.995030  0.993121\n",
       "9       macro avg f1-score      0.991871  0.993121\n",
       "10  weighted avg precision      0.993892  0.994781\n",
       "11     weighted avg recall      0.993789  0.994781\n",
       "12   weighted avg f1-score      0.993808  0.994781"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Metric  Simple Split    K-Fold\n",
      "0              0 precision      0.999161  0.996500\n",
      "1                 0 recall      0.992500  0.996500\n",
      "2               0 f1-score      0.995819  0.996500\n",
      "3              1 precision      0.978469  0.989741\n",
      "4                 1 recall      0.997561  0.989741\n",
      "5               1 f1-score      0.987923  0.989741\n",
      "6                 Accuracy      0.993789  0.994781\n",
      "7      macro avg precision      0.988815  0.993121\n",
      "8         macro avg recall      0.995030  0.993121\n",
      "9       macro avg f1-score      0.991871  0.993121\n",
      "10  weighted avg precision      0.993892  0.994781\n",
      "11     weighted avg recall      0.993789  0.994781\n",
      "12   weighted avg f1-score      0.993808  0.994781\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "result_df = pd.DataFrame(comparison)\n",
    "display(result_df)\n",
    "\n",
    "# 콘솔에서 직접 출력\n",
    "print(result_df)\n",
    "\n",
    "# 또는 CSV 파일로 저장\n",
    "result_df.to_csv(\"../../dataset/model_comparison_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c4dfa5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../models/pipeline_kfold.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 저장\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# 모델 저장 디렉토리 만들기\n",
    "os.makedirs(\"../../models\", exist_ok=True)\n",
    "\n",
    "# 1. Simple Split 모델 저장\n",
    "joblib.dump(pipeline_simple, \"../../models/pipeline_simple.pkl\")\n",
    "\n",
    "# 2. K-Fold 모델 → 전체 데이터로 다시 학습 후 저장\n",
    "pipeline_kfold.fit(X, y)\n",
    "joblib.dump(pipeline_kfold, \"../../models/pipeline_kfold.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc87701c",
   "metadata": {},
   "source": [
    "# 피싱 논피싱 단순 판별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9526b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 저장된 모델 불러오기\n",
    "loaded_model = joblib.load(\"../../models/1차모델_원본데이터_pipeline_Ngram_kfold.pkl\")\n",
    "loaded_model.predict([\"수사기관을 사칭하고 계좌를 요구하는 대화입니다\"])  # 판별할 문장을 넣는곳"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b303c9ed",
   "metadata": {},
   "source": [
    "# 퍼센테이지로 구간 별로 판별함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad870532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "import joblib\n",
    "\n",
    "loaded_model = joblib.load(\"../../models/1차모델_원본데이터_pipeline_Ngram_kfold.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26eca76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_with_hold(prob, low=0.3, high=0.7):\n",
    "    if prob < low:\n",
    "        return 0  # 일반 대화\n",
    "    elif prob > high:\n",
    "        return 1  # 보이스피싱\n",
    "    else:\n",
    "        return -1  # 보류 → 2차 모델로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0272c305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 확률: 0.6084\n",
      "1차 판별 결과: -1 (0: 일반, 1: 피싱, -1: 보류)\n"
     ]
    }
   ],
   "source": [
    "# 예측 대상 문장\n",
    "input_text = [\n",
    "    \"그러시면 71년생 남성 사람은 아십니까? 지금 강성호 씨는 돈을 주고 샀다고 짓을 하는데 본인께서 감상으로 저녁 먹읍시다 말씀이세요. 알다시피 금융거래실명법 원칙에 따라 통장을 개설하면 본인이 직접 신분증을 지참하고 은행에 가서 하지 마 통장 발급 되지 않습니까네? 본인이 모른다고 해서 5만 원은 살 거는 아니고요. 보이 입장도 이해를 하고 환경을 수 없지만요. 이번 사건은 방송을 하는 사람이 불법도박사이트로 운영하면서 대포통장이 필요하니까 50원을 포함한 전국의 132명의 자들에게 통장을 구매했다고 짓을 해서 연락을 드리면 부분이고요.\"\n",
    "]  \n",
    "\n",
    "# 보이스피싱(클래스 1) 확률만 추출\n",
    "proba = loaded_model.predict_proba(input_text)[0][1]\n",
    "\n",
    "# 보류 구간 판별 적용\n",
    "final_result = classify_with_hold(proba)\n",
    "\n",
    "print(f\"예측 확률: {proba:.4f}\")\n",
    "print(f\"1차 판별 결과: {final_result} (0: 일반, 1: 피싱, -1: 보류)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d824a3",
   "metadata": {},
   "source": [
    "# 앙상블 Bagging 1차 모델 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "504efb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6000\n",
      "           1       1.00      0.96      0.98      2047\n",
      "\n",
      "    accuracy                           0.99      8047\n",
      "   macro avg       0.99      0.98      0.99      8047\n",
      "weighted avg       0.99      0.99      0.99      8047\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../../models/1차모델_원본데이터_pipeline_rf.pkl']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from kiwipiepy import Kiwi\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# 데이터 로드\n",
    "data_path = \"../../dataset/merged_labeled_data.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Kiwi 토큰화 + 표제어 처리\n",
    "kiwi = Kiwi()\n",
    "\n",
    "\n",
    "def tokenize_and_filter(text):\n",
    "    result = kiwi.analyze(text)[0][0]\n",
    "    tokens = []\n",
    "    for word, pos, _, _ in result:\n",
    "        if pos in {\"NNG\", \"NNP\", \"VV\", \"VA\"}:\n",
    "            if pos in {\"VV\", \"VA\"}:\n",
    "                word = word + \"다\"\n",
    "            tokens.append(word)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "df[\"processed_text\"] = df[\"text\"].astype(str).apply(tokenize_and_filter)\n",
    "\n",
    "X = df[\"processed_text\"]\n",
    "y = df[\"is_phishing\"]\n",
    "\n",
    "# ▶ 앙상블 모델 파이프라인 (TF-IDF + RandomForest)\n",
    "pipeline_rf = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"tfidf\",\n",
    "            TfidfVectorizer(\n",
    "                sublinear_tf=True, min_df=5, max_df=0.9, ngram_range=(1, 2)\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"clf\",\n",
    "            RandomForestClassifier(\n",
    "                n_estimators=100, random_state=42, class_weight=\"balanced\"\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ▶ K-Fold 교차 검증 성능 측정\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "y_pred_rf = cross_val_predict(pipeline_rf, X, y, cv=skf)\n",
    "\n",
    "# ▶ 성능 리포트 출력\n",
    "report_rf = classification_report(y, y_pred_rf, output_dict=False)\n",
    "print(report_rf)\n",
    "\n",
    "# ▶ 전체 데이터로 다시 학습 후 저장\n",
    "pipeline_rf.fit(X, y)\n",
    "\n",
    "# 저장 경로\n",
    "os.makedirs(\"../../models\", exist_ok=True)\n",
    "joblib.dump(pipeline_rf, \"../../models/1차모델_원본데이터_pipeline_rf.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd199ff",
   "metadata": {},
   "source": [
    "# 앙상블 Stacking 1차 모델 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3b759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from kiwipiepy import Kiwi\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.ensemble import (\n",
    "    StackingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# 1. 데이터 불러오기\n",
    "df = pd.read_csv(\"../../dataset/merged_labeled_data.csv\")\n",
    "\n",
    "# 2. 형태소 분석기 설정\n",
    "kiwi = Kiwi()\n",
    "\n",
    "\n",
    "def tokenize_and_filter(text):\n",
    "    result = kiwi.analyze(text)[0][0]\n",
    "    tokens = []\n",
    "    for word, pos, _, _ in result:\n",
    "        if pos in {\"NNG\", \"NNP\", \"VV\", \"VA\"}:\n",
    "            if pos in {\"VV\", \"VA\"}:\n",
    "                word += \"다\"\n",
    "            tokens.append(word)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "# 3. 전처리\n",
    "df[\"processed_text\"] = df[\"text\"].astype(str).apply(tokenize_and_filter)\n",
    "X = df[\"processed_text\"]\n",
    "y = df[\"is_phishing\"]\n",
    "\n",
    "# 4. 스태킹 모델 구성\n",
    "base_models = [\n",
    "    (\"lr\", LogisticRegression(max_iter=1000, class_weight=\"balanced\")),\n",
    "    (\n",
    "        \"rf\",\n",
    "        RandomForestClassifier(\n",
    "            n_estimators=100, class_weight=\"balanced\", random_state=42\n",
    "        ),\n",
    "    ),\n",
    "    (\"gb\", GradientBoostingClassifier(n_estimators=100, random_state=42)),\n",
    "]\n",
    "\n",
    "meta_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "stacked_clf = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5,  # 내부에서 K-Fold\n",
    "    n_jobs=-1,\n",
    "    passthrough=False,  # True면 base 모델의 입력도 같이 전달됨\n",
    ")\n",
    "\n",
    "# 5. 전체 파이프라인 (TF-IDF → 스태킹 모델)\n",
    "pipeline_stacking = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"tfidf\",\n",
    "            TfidfVectorizer(\n",
    "                sublinear_tf=True, min_df=5, max_df=0.9, ngram_range=(1, 2)\n",
    "            ),\n",
    "        ),\n",
    "        (\"clf\", stacked_clf),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 6. K-Fold 기반 평가\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "y_pred_stack = cross_val_predict(pipeline_stacking, X, y, cv=skf)\n",
    "\n",
    "# 7. 성능 출력\n",
    "report = classification_report(y, y_pred_stack)\n",
    "print(report)\n",
    "\n",
    "# 8. 최종 전체 학습 및 저장\n",
    "pipeline_stacking.fit(X, y)\n",
    "os.makedirs(\"../../models\", exist_ok=True)\n",
    "joblib.dump(pipeline_stacking, \"../../models/pipeline_stacking.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd672e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "woogawooga_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
