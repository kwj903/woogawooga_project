{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc8f103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.93.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.14.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (2.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python313\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python313\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openai pandas\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2949d5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API 키 앞 10자리: sk-proj--a\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(\"API 키 앞 10자리:\", api_key[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a9939e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 보이스피싱 대화 생성 중...\n",
      "생성 중: 대출빙자형 1 ~ 5 (파일명 시작: phishing_001)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 대출빙자형 6 ~ 10 (파일명 시작: phishing_006)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 대출빙자형 11 ~ 15 (파일명 시작: phishing_011)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 대출빙자형 16 ~ 20 (파일명 시작: phishing_016)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 대출빙자형 21 ~ 25 (파일명 시작: phishing_021)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 대출빙자형 26 ~ 30 (파일명 시작: phishing_026)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 대출빙자형 31 ~ 35 (파일명 시작: phishing_031)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 대출빙자형 36 ~ 40 (파일명 시작: phishing_036)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 대출빙자형 41 ~ 45 (파일명 시작: phishing_041)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 대출빙자형 46 ~ 50 (파일명 시작: phishing_046)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 대출빙자형 51 ~ 55 (파일명 시작: phishing_051)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 대출빙자형 56 ~ 60 (파일명 시작: phishing_056)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 대출빙자형 61 ~ 65 (파일명 시작: phishing_061)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 대출빙자형 66 ~ 70 (파일명 시작: phishing_066)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 대출빙자형 71 ~ 75 (파일명 시작: phishing_071)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 대출빙자형 76 ~ 80 (파일명 시작: phishing_076)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 대출빙자형 81 ~ 85 (파일명 시작: phishing_081)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 대출빙자형 86 ~ 90 (파일명 시작: phishing_086)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 대출빙자형 91 ~ 95 (파일명 시작: phishing_091)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 대출빙자형 96 ~ 100 (파일명 시작: phishing_096)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 메신저 피싱형 1 ~ 5 (파일명 시작: phishing_101)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 메신저 피싱형 6 ~ 10 (파일명 시작: phishing_106)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 메신저 피싱형 11 ~ 15 (파일명 시작: phishing_111)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 메신저 피싱형 16 ~ 20 (파일명 시작: phishing_116)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 메신저 피싱형 21 ~ 25 (파일명 시작: phishing_121)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 메신저 피싱형 26 ~ 30 (파일명 시작: phishing_126)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 메신저 피싱형 31 ~ 35 (파일명 시작: phishing_131)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 메신저 피싱형 36 ~ 40 (파일명 시작: phishing_136)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 메신저 피싱형 41 ~ 45 (파일명 시작: phishing_141)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 메신저 피싱형 46 ~ 50 (파일명 시작: phishing_146)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 메신저 피싱형 51 ~ 55 (파일명 시작: phishing_151)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 메신저 피싱형 56 ~ 60 (파일명 시작: phishing_156)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 메신저 피싱형 61 ~ 65 (파일명 시작: phishing_161)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 메신저 피싱형 66 ~ 70 (파일명 시작: phishing_166)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 메신저 피싱형 71 ~ 75 (파일명 시작: phishing_171)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 메신저 피싱형 76 ~ 80 (파일명 시작: phishing_176)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 메신저 피싱형 81 ~ 85 (파일명 시작: phishing_181)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 메신저 피싱형 86 ~ 90 (파일명 시작: phishing_186)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 메신저 피싱형 91 ~ 95 (파일명 시작: phishing_191)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 메신저 피싱형 96 ~ 100 (파일명 시작: phishing_196)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 택배사칭형 1 ~ 5 (파일명 시작: phishing_201)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 택배사칭형 6 ~ 10 (파일명 시작: phishing_206)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 택배사칭형 11 ~ 15 (파일명 시작: phishing_211)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 택배사칭형 16 ~ 20 (파일명 시작: phishing_216)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 택배사칭형 21 ~ 25 (파일명 시작: phishing_221)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 택배사칭형 26 ~ 30 (파일명 시작: phishing_226)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 택배사칭형 31 ~ 35 (파일명 시작: phishing_231)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 택배사칭형 36 ~ 40 (파일명 시작: phishing_236)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 택배사칭형 41 ~ 45 (파일명 시작: phishing_241)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 택배사칭형 46 ~ 50 (파일명 시작: phishing_246)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 택배사칭형 51 ~ 55 (파일명 시작: phishing_251)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 택배사칭형 56 ~ 60 (파일명 시작: phishing_256)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 택배사칭형 61 ~ 65 (파일명 시작: phishing_261)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 택배사칭형 66 ~ 70 (파일명 시작: phishing_266)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 택배사칭형 71 ~ 75 (파일명 시작: phishing_271)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 택배사칭형 76 ~ 80 (파일명 시작: phishing_276)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 택배사칭형 81 ~ 85 (파일명 시작: phishing_281)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 택배사칭형 86 ~ 90 (파일명 시작: phishing_286)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 택배사칭형 91 ~ 95 (파일명 시작: phishing_291)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 택배사칭형 96 ~ 100 (파일명 시작: phishing_296)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n"
     ]
    }
   ],
   "source": [
    "# GPT-4o 모델을 사용하여 보이스피싱 대화 시나리오(대출빙자형, 메신저 피싱형, 택배사칭형)를 자동으로 생성하고, \n",
    "# 생성된 데이터를 중복 없이 CSV 파일로 저장하는 자동화 파이프라인입니다.\n",
    "# 각 대화는 3~10문장으로 구성되며, 피싱범(0)과 피해자(1)가 번갈아가며 대화하고, 한 대화에는 한 가지 유형만 포함됩니다.\n",
    "# 대화 파일명은 phishing_001처럼 순차적으로 부여되고, 모든 대화에서 이름은 'OOO'만 사용하며, 실제적이고 자연스러운 시나리오만 생성됩니다.\n",
    "# 생성된 데이터는 기존 CSV와 합쳐 중복을 제거한 뒤 저장됩니다.\n",
    "# RateLimitError 등 예외 상황도 처리합니다.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI, RateLimitError\n",
    "\n",
    "# 1. 환경 변수 로드 및 API 키 확인\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"❌ API 키가 로드되지 않았습니다. .env 파일을 확인하세요.\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# 2. 시스템 프롬프트 (영어, 출력은 반드시 한국어)\n",
    "system_prompt = \"\"\"\n",
    "You are a financial crime investigation expert with 15 years of experience and a developer of voice phishing detection systems.\n",
    "Please create realistic and natural phone call scenarios for building a voice phishing detection dataset.\n",
    "\n",
    "Rules:\n",
    "1. Each conversation consists of 3 to 10 sentences, with a balanced distribution of sentence counts across conversations.\n",
    "2. The phishing scammer (0) and the victim (1) alternate in the conversation.\n",
    "3. Only generate three types of conversations: loan fraud, messenger phishing, and delivery impersonation.\n",
    "4. Each conversation should contain only one type.\n",
    "5. Use the name 'OOO' exclusively in all conversations (e.g., \"Hello, is this OOO? This is regarding a loan.\").\n",
    "6. Make the conversations realistic and natural without duplication. Avoid overlapping with previously generated conversations.\n",
    "7. Output the results in the following CSV format (without headers):\n",
    "\n",
    "phishing_001,loan fraud,0,Hello, is this OOO? I am contacting you regarding a loan.\n",
    "phishing_001,loan fraud,1,Yes? What is this about?\n",
    "(Generate 5 conversations from phishing_001 to phishing_005.)\n",
    "\n",
    "Please output the conversation text in Korean.\n",
    "\"\"\"\n",
    "\n",
    "# 3. GPT-4o로 시나리오 생성\n",
    "def generate_phishing_dialogues(n, start_index, conversation_type):\n",
    "    # conversation_type을 영어로 변환\n",
    "    type_en = {\n",
    "        \"대출빙자형\": \"loan fraud\",\n",
    "        \"메신저 피싱형\": \"messenger phishing\",\n",
    "        \"택배사칭형\": \"delivery impersonation\"\n",
    "    }[conversation_type]\n",
    "    user_prompt = (\n",
    "        f\"Please generate {n} {type_en} voice phishing scenarios. \"\n",
    "        f\"File names should be assigned sequentially from phishing_{start_index:03d}.\"\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.8\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# 4. 생성 결과를 CSV에 누적 저장(중복 제거)\n",
    "def parse_and_save_csv_append_unique(response_text, save_path=\"./dataset/phishing_data.csv\"):\n",
    "    lines = [line.strip() for line in response_text.strip().split(\"\\n\") if line and not line.startswith(\"file_name\")]\n",
    "    data = [line.split(\",\", maxsplit=3) for line in lines if len(line.split(\",\", maxsplit=3)) == 4]\n",
    "    df_new = pd.DataFrame(data, columns=[\"file_name\", \"conversation_type\", \"spk\", \"msg\"])\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    if os.path.exists(save_path):\n",
    "        df_existing = pd.read_csv(save_path)\n",
    "        df_combined = pd.concat([df_existing, df_new], ignore_index=True)\n",
    "        df_combined.drop_duplicates(inplace=True)\n",
    "        df_combined.to_csv(save_path, index=False, encoding=\"utf-8-sig\")\n",
    "    else:\n",
    "        df_new.to_csv(save_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✅ CSV 저장 완료 및 중복 제거: {save_path}\")\n",
    "\n",
    "# 5. 실행\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🔄 보이스피싱 대화 생성 중...\")\n",
    "    try:\n",
    "        total_count = 300\n",
    "        batch_size = 5\n",
    "        conversation_types = [\"대출빙자형\", \"메신저 피싱형\", \"택배사칭형\"]\n",
    "        count_per_type = total_count // len(conversation_types)  # 100개씩\n",
    "        start_index = 1\n",
    "        for ctype in conversation_types:\n",
    "            for i in range(0, count_per_type, batch_size):\n",
    "                print(f\"생성 중: {ctype} {i+1} ~ {i+batch_size} (파일명 시작: phishing_{start_index:03d})\")\n",
    "                output = generate_phishing_dialogues(batch_size, start_index, ctype)\n",
    "                parse_and_save_csv_append_unique(output, save_path=\"./dataset/phishing_data.csv\")\n",
    "                start_index += batch_size\n",
    "    except RateLimitError:\n",
    "        print(\"❌ RateLimitError: 쿼터 초과 또는 모델 접근 제한입니다. 잠시 후 재시도하거나 대시보드를 확인하세요.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류 발생: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d35058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 기관사칭형 보이스피싱 대화 생성 중...\n",
      "생성 중: 301 ~ 305 (파일명 시작: phishing_301)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 306 ~ 310 (파일명 시작: phishing_306)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 311 ~ 315 (파일명 시작: phishing_311)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 316 ~ 320 (파일명 시작: phishing_316)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 321 ~ 325 (파일명 시작: phishing_321)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 326 ~ 330 (파일명 시작: phishing_326)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 331 ~ 335 (파일명 시작: phishing_331)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 336 ~ 340 (파일명 시작: phishing_336)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 341 ~ 345 (파일명 시작: phishing_341)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 346 ~ 350 (파일명 시작: phishing_346)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 351 ~ 355 (파일명 시작: phishing_351)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 356 ~ 360 (파일명 시작: phishing_356)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 361 ~ 365 (파일명 시작: phishing_361)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 366 ~ 370 (파일명 시작: phishing_366)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 371 ~ 375 (파일명 시작: phishing_371)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 376 ~ 380 (파일명 시작: phishing_376)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 381 ~ 385 (파일명 시작: phishing_381)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 386 ~ 390 (파일명 시작: phishing_386)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 391 ~ 395 (파일명 시작: phishing_391)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 396 ~ 400 (파일명 시작: phishing_396)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 401 ~ 405 (파일명 시작: phishing_401)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 406 ~ 410 (파일명 시작: phishing_406)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 411 ~ 415 (파일명 시작: phishing_411)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 416 ~ 420 (파일명 시작: phishing_416)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 421 ~ 425 (파일명 시작: phishing_421)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 426 ~ 430 (파일명 시작: phishing_426)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 431 ~ 435 (파일명 시작: phishing_431)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 436 ~ 440 (파일명 시작: phishing_436)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 441 ~ 445 (파일명 시작: phishing_441)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 446 ~ 450 (파일명 시작: phishing_446)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 451 ~ 455 (파일명 시작: phishing_451)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 456 ~ 460 (파일명 시작: phishing_456)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 461 ~ 465 (파일명 시작: phishing_461)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 466 ~ 470 (파일명 시작: phishing_466)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 471 ~ 475 (파일명 시작: phishing_471)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 476 ~ 480 (파일명 시작: phishing_476)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 481 ~ 485 (파일명 시작: phishing_481)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 486 ~ 490 (파일명 시작: phishing_486)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 491 ~ 495 (파일명 시작: phishing_491)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 496 ~ 500 (파일명 시작: phishing_496)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 501 ~ 505 (파일명 시작: phishing_501)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 506 ~ 510 (파일명 시작: phishing_506)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 511 ~ 515 (파일명 시작: phishing_511)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 516 ~ 520 (파일명 시작: phishing_516)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 521 ~ 525 (파일명 시작: phishing_521)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 526 ~ 530 (파일명 시작: phishing_526)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 531 ~ 535 (파일명 시작: phishing_531)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 536 ~ 540 (파일명 시작: phishing_536)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 541 ~ 545 (파일명 시작: phishing_541)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 546 ~ 550 (파일명 시작: phishing_546)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 551 ~ 555 (파일명 시작: phishing_551)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 556 ~ 560 (파일명 시작: phishing_556)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 561 ~ 565 (파일명 시작: phishing_561)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 566 ~ 570 (파일명 시작: phishing_566)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 571 ~ 575 (파일명 시작: phishing_571)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 576 ~ 580 (파일명 시작: phishing_576)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 581 ~ 585 (파일명 시작: phishing_581)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 586 ~ 590 (파일명 시작: phishing_586)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 591 ~ 595 (파일명 시작: phishing_591)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: 596 ~ 600 (파일명 시작: phishing_596)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n"
     ]
    }
   ],
   "source": [
    "# GPT-4o 모델을 사용하여 기관사칭형(경찰, 검찰, 은행, 세무서, 보험 등) 보이스피싱 대화 시나리오를 자동으로 생성하고, \n",
    "# 생성된 데이터를 중복 없이 CSV 파일로 저장하는 자동화 파이프라인입니다.  \n",
    "# 각 대화는 3~10문장으로 구성되며, 피싱범(0)과 피해자(1)가 번갈아가며 대화하고, 한 대화에는 기관사칭형 유형만 포함됩니다.  \n",
    "# 대화 파일명은 phishing_001처럼 순차적으로 부여되고, 모든 대화에서 이름은 'OOO'만 사용하며, 실제적이고 자연스러운 시나리오만 생성됩니다.  \n",
    "# 기관사칭 범죄의 다양성을 위해 사칭 기관(경찰, 검찰, 은행, 세무서, 보험 등)과 피해자 반응(의심, 순응, 당황, 저항 등)이 다양하게 포함됩니다.  \n",
    "# 생성된 데이터는 기존 CSV와 합쳐 중복을 제거한 뒤 저장되며, RateLimitError 등 예외 상황도 처리합니다.\n",
    "\n",
    "# 1. 환경 변수 로드 및 API 키 확인\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"❌ API 키가 로드되지 않았습니다. .env 파일을 확인하세요.\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# 2. 시스템 프롬프트 (기관사칭형, 영어 프롬프트, 출력은 반드시 한국어)\n",
    "system_prompt = \"\"\"\n",
    "You are a financial crime investigation expert with 15 years of experience and a developer of voice phishing detection systems.\n",
    "Please create realistic and natural phone call scenarios for building a voice phishing detection dataset.\n",
    "\n",
    "Rules:\n",
    "1. Each conversation must be of the 'authority impersonation' (기관사칭형) type only.\n",
    "2. Each conversation consists of 3 to 10 sentences, and the number of sentences should be evenly distributed across the dataset.\n",
    "3. The scammer (0) and the victim (1) alternate in the conversation.\n",
    "4. Only one conversation type per dialogue.\n",
    "5. Always use the name 'OOO' in all conversations (e.g., \"Hello, is this OOO?\").\n",
    "6. Make the conversations realistic, natural, and highly diverse. Vary the impersonated institutions (e.g., police, prosecutors, banks, tax office, insurance, etc.) and ensure the victim's responses are also diverse (suspicious, compliant, confused, resistant, etc.).\n",
    "7. Avoid duplication with previously generated conversations.\n",
    "8. Output the results in the following CSV format (without headers):\n",
    "\n",
    "phishing_001,authority impersonation,0,Hello, is this OOO? This is Inspector Kim from the Seoul Metropolitan Police.\n",
    "phishing_001,authority impersonation,1,Yes, that's me. What's going on?\n",
    "(Generate 5 conversations from phishing_001 to phishing_005.)\n",
    "\n",
    "Please output the conversation text in Korean.\n",
    "\"\"\"\n",
    "\n",
    "# 3. 기존 CSV에서 마지막 file_name의 번호를 읽어오는 함수\n",
    "def get_next_start_index(save_path=\"./dataset/phishing_data.csv\"):\n",
    "    if os.path.exists(save_path):\n",
    "        df = pd.read_csv(save_path)\n",
    "        # file_name에서 숫자 부분만 추출해서 가장 큰 번호를 찾음\n",
    "        max_idx = (\n",
    "            df[\"file_name\"]\n",
    "            .str.extract(r'phishing_(\\d+)')[0]\n",
    "            .dropna()\n",
    "            .astype(int)\n",
    "            .max()\n",
    "        )\n",
    "        return int(max_idx) + 1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# 4. GPT-4o로 시나리오 생성\n",
    "def generate_phishing_dialogues(n, start_index):\n",
    "    user_prompt = (\n",
    "        f\"Please generate {n} authority impersonation voice phishing scenarios. \"\n",
    "        f\"File names should be assigned sequentially from phishing_{start_index:03d}.\"\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.8\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# 5. 생성 결과를 CSV에 누적 저장(중복 제거)\n",
    "def parse_and_save_csv_append_unique(response_text, save_path=\"./dataset/phishing_data.csv\"):\n",
    "    lines = [line.strip() for line in response_text.strip().split(\"\\n\") if line and not line.startswith(\"file_name\")]\n",
    "    data = [line.split(\",\", maxsplit=3) for line in lines if len(line.split(\",\", maxsplit=3)) == 4]\n",
    "    df_new = pd.DataFrame(data, columns=[\"file_name\", \"conversation_type\", \"spk\", \"msg\"])\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    if os.path.exists(save_path):\n",
    "        df_existing = pd.read_csv(save_path)\n",
    "        df_combined = pd.concat([df_existing, df_new], ignore_index=True)\n",
    "        df_combined.drop_duplicates(inplace=True)\n",
    "        df_combined.to_csv(save_path, index=False, encoding=\"utf-8-sig\")\n",
    "    else:\n",
    "        df_new.to_csv(save_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✅ CSV 저장 완료 및 중복 제거: {save_path}\")\n",
    "\n",
    "# 6. 실행\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🔄 기관사칭형 보이스피싱 대화 생성 중...\")\n",
    "    try:\n",
    "        total_count = 300      # 새로 생성할 총 대화 개수\n",
    "        batch_size = 5         # 한 번에 생성할 개수\n",
    "        save_path = \"./dataset/phishing_data.csv\"\n",
    "        start_index = get_next_start_index(save_path)  # 기존 데이터가 있으면 다음 번호부터 시작\n",
    "        for i in range(0, total_count, batch_size):\n",
    "            print(f\"생성 중: {start_index} ~ {start_index+batch_size-1} (파일명 시작: phishing_{start_index:03d})\")\n",
    "            output = generate_phishing_dialogues(batch_size, start_index)\n",
    "            parse_and_save_csv_append_unique(output, save_path=save_path)\n",
    "            start_index += batch_size\n",
    "    except RateLimitError:\n",
    "        print(\"❌ RateLimitError: 쿼터 초과 또는 모델 접근 제한입니다. 잠시 후 재시도하거나 대시보드를 확인하세요.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류 발생: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7754efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 보이스피싱 대화 생성 중...\n",
      "생성 중: authority impersonation 701 ~ 705 (파일명 시작: phishing_701)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: authority impersonation 706 ~ 710 (파일명 시작: phishing_706)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: authority impersonation 711 ~ 715 (파일명 시작: phishing_711)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: authority impersonation 716 ~ 720 (파일명 시작: phishing_716)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: authority impersonation 721 ~ 725 (파일명 시작: phishing_721)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: authority impersonation 726 ~ 730 (파일명 시작: phishing_726)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: authority impersonation 731 ~ 735 (파일명 시작: phishing_731)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: authority impersonation 736 ~ 740 (파일명 시작: phishing_736)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: loan fraud 741 ~ 745 (파일명 시작: phishing_741)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: loan fraud 746 ~ 750 (파일명 시작: phishing_746)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: loan fraud 751 ~ 755 (파일명 시작: phishing_751)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: loan fraud 756 ~ 760 (파일명 시작: phishing_756)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: messenger phishing 761 ~ 765 (파일명 시작: phishing_761)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: messenger phishing 766 ~ 770 (파일명 시작: phishing_766)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: messenger phishing 771 ~ 775 (파일명 시작: phishing_771)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: messenger phishing 776 ~ 780 (파일명 시작: phishing_776)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: parcel scam 781 ~ 785 (파일명 시작: phishing_781)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: parcel scam 786 ~ 790 (파일명 시작: phishing_786)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: parcel scam 791 ~ 795 (파일명 시작: phishing_791)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: parcel scam 796 ~ 800 (파일명 시작: phishing_796)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n"
     ]
    }
   ],
   "source": [
    "# GPT-4o 모델을 활용하여 보이스피싱 시나리오(기관사칭형, 대출빙자형, 메신저피싱형, 택배사기형)를 자동으로 생성하고, \n",
    "# 생성된 데이터를 중복 없이 CSV 파일로 저장하는 자동화 파이프라인입니다.  \n",
    "# 각 시나리오 유형별로 문장 수(기관사칭/대출빙자/메신저피싱: 8~12문장, 택배사기: 13~15문장)를 다르게 설정하며, \n",
    "# 피싱범(0)과 피해자(1)가 번갈아 대화하고, 한 대화에는 한 가지 유형만 포함됩니다.  \n",
    "# 대화 파일명은 phishing_001처럼 순차적으로 부여되고, 모든 대화에서 이름은 'OOO'만 사용합니다.  \n",
    "# 각 유형별로 사칭 기관·대출 종류·메신저·택배사 등과 피해자 반응(의심, 순응, 당황, 저항 등)이 다양하게 포함되도록 \n",
    "# 프롬프트가 설계되어 있습니다.  \n",
    "# 생성된 데이터는 기존 CSV와 합쳐 중복을 제거한 뒤 저장되며, RateLimitError 등 예외 상황도 처리합니다.\n",
    "\n",
    "# 1. 환경 변수 로드 및 API 키 확인\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"❌ API 키가 로드되지 않았습니다. .env 파일을 확인하세요.\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# 2. 시스템 프롬프트 (문장 수 8~12로, 유형별 안내)\n",
    "system_prompt_dict = {\n",
    "    \"authority impersonation\": \"\"\"\n",
    "You are a financial crime investigation expert with 15 years of experience and a developer of voice phishing detection systems.\n",
    "Please create realistic and natural phone call scenarios for building a voice phishing detection dataset.\n",
    "\n",
    "Rules:\n",
    "1. Each conversation must be of the 'authority impersonation' (기관사칭형) type only.\n",
    "2. Each conversation consists of 8 to 12 sentences, and the number of sentences should be evenly distributed across the dataset.\n",
    "3. The scammer (0) and the victim (1) alternate in the conversation.\n",
    "4. Only one conversation type per dialogue.\n",
    "5. Always use the name 'OOO' in all conversations (e.g., \"Hello, is this OOO?\").\n",
    "6. Make the conversations realistic, natural, and highly diverse. Vary the impersonated institutions (e.g., police, prosecutors, banks, tax office, insurance, etc.) and ensure the victim's responses are also diverse (suspicious, compliant, confused, resistant, etc.).\n",
    "7. Avoid duplication with previously generated conversations.\n",
    "8. Output the results in the following CSV format (without headers):\n",
    "\n",
    "phishing_001,authority impersonation,0,Hello, is this OOO? This is Inspector Kim from the Seoul Metropolitan Police.\n",
    "phishing_001,authority impersonation,1,Yes, that's me. What's going on?\n",
    "(Generate 5 conversations from phishing_001 to phishing_005.)\n",
    "\n",
    "Please output the conversation text in Korean.\n",
    "\"\"\",\n",
    "    \"loan fraud\": \"\"\"\n",
    "You are a financial crime investigation expert with 15 years of experience and a developer of voice phishing detection systems.\n",
    "Please create realistic and natural phone call scenarios for building a voice phishing detection dataset.\n",
    "\n",
    "Rules:\n",
    "1. Each conversation must be of the 'loan fraud' (대출빙자형) type only.\n",
    "2. Each conversation consists of 8 to 12 sentences, and the number of sentences should be evenly distributed across the dataset.\n",
    "3. The scammer (0) and the victim (1) alternate in the conversation.\n",
    "4. Only one conversation type per dialogue.\n",
    "5. Always use the name 'OOO' in all conversations (e.g., \"Hello, is this OOO?\").\n",
    "6. Make the conversations realistic, natural, and highly diverse. Vary the loan types and ensure the victim's responses are also diverse (suspicious, compliant, confused, resistant, etc.).\n",
    "7. Avoid duplication with previously generated conversations.\n",
    "8. Output the results in the following CSV format (without headers):\n",
    "\n",
    "phishing_001,loan fraud,0,Hello, is this OOO? I am calling regarding a special loan offer.\n",
    "phishing_001,loan fraud,1,Yes? What is this about?\n",
    "(Generate 5 conversations from phishing_001 to phishing_005.)\n",
    "\n",
    "Please output the conversation text in Korean.\n",
    "\"\"\",\n",
    "    \"messenger phishing\": \"\"\"\n",
    "You are a financial crime investigation expert with 15 years of experience and a developer of voice phishing detection systems.\n",
    "Please create realistic and natural phone call scenarios for building a voice phishing detection dataset.\n",
    "\n",
    "Rules:\n",
    "1. Each conversation must be of the 'messenger phishing' (메신저피싱형) type only.\n",
    "2. Each conversation consists of 8 to 12 sentences, and the number of sentences should be evenly distributed across the dataset.\n",
    "3. The scammer (0) and the victim (1) alternate in the conversation.\n",
    "4. Only one conversation type per dialogue.\n",
    "5. Always use the name 'OOO' in all conversations (e.g., \"Hello, is this OOO?\").\n",
    "6. Make the conversations realistic, natural, and highly diverse. Vary the impersonated messenger types and ensure the victim's responses are also diverse (suspicious, compliant, confused, resistant, etc.).\n",
    "7. Avoid duplication with previously generated conversations.\n",
    "8. Output the results in the following CSV format (without headers):\n",
    "\n",
    "phishing_001,messenger phishing,0,Hello, is this OOO? I'm contacting you through your messenger app.\n",
    "phishing_001,messenger phishing,1,Yes, this is OOO. Who is this?\n",
    "(Generate 5 conversations from phishing_001 to phishing_005.)\n",
    "\n",
    "Please output the conversation text in Korean.\n",
    "\"\"\",\n",
    "    \"parcel scam\": \"\"\"\n",
    "You are a financial crime investigation expert with 15 years of experience and a developer of voice phishing detection systems.\n",
    "Please create realistic and natural phone call scenarios for building a voice phishing detection dataset.\n",
    "\n",
    "Rules:\n",
    "1. Each conversation must be of the 'parcel scam' (택배사기형) type only.\n",
    "2. Each conversation consists of 13 to 15 sentences, and the number of sentences should be evenly distributed across the dataset.\n",
    "3. The scammer (0) and the victim (1) alternate in the conversation.\n",
    "4. Only one conversation type per dialogue.\n",
    "5. Always use the name 'OOO' in all conversations (e.g., \"Hello, is this OOO?\").\n",
    "6. Make the conversations realistic, natural, and highly diverse. Vary the delivery companies and ensure the victim's responses are also diverse (suspicious, compliant, confused, resistant, etc.).\n",
    "7. Avoid duplication with previously generated conversations.\n",
    "8. Output the results in the following CSV format (without headers):\n",
    "\n",
    "phishing_001,parcel scam,0,Hello, is this OOO? I'm calling from the delivery service.\n",
    "phishing_001,parcel scam,1,Yes, this is OOO. Is there a problem with my parcel?\n",
    "(Generate 5 conversations from phishing_001 to phishing_005.)\n",
    "\n",
    "Please output the conversation text in Korean.\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "# 3. 기존 CSV에서 마지막 file_name의 번호를 읽어오는 함수\n",
    "def get_next_start_index(save_path=\"./dataset/phishing_data.csv\"):\n",
    "    if os.path.exists(save_path):\n",
    "        df = pd.read_csv(save_path)\n",
    "        max_idx = (\n",
    "            df[\"file_name\"]\n",
    "            .str.extract(r'phishing_(\\d+)')[0]\n",
    "            .dropna()\n",
    "            .astype(int)\n",
    "            .max()\n",
    "        )\n",
    "        return int(max_idx) + 1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# 4. GPT-4o로 시나리오 생성\n",
    "def generate_phishing_dialogues(n, start_index, scenario_type):\n",
    "    user_prompt = (\n",
    "        f\"Please generate {n} {scenario_type} voice phishing scenarios. \"\n",
    "        f\"File names should be assigned sequentially from phishing_{start_index:03d}.\"\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt_dict[scenario_type]},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.8\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# 5. 생성 결과를 CSV에 누적 저장(중복 제거)\n",
    "def parse_and_save_csv_append_unique(response_text, save_path=\"./dataset/phishing_data.csv\"):\n",
    "    lines = [line.strip() for line in response_text.strip().split(\"\\n\") if line and not line.startswith(\"file_name\")]\n",
    "    data = [line.split(\",\", maxsplit=3) for line in lines if len(line.split(\",\", maxsplit=3)) == 4]\n",
    "    df_new = pd.DataFrame(data, columns=[\"file_name\", \"conversation_type\", \"spk\", \"msg\"])\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    if os.path.exists(save_path):\n",
    "        df_existing = pd.read_csv(save_path)\n",
    "        df_combined = pd.concat([df_existing, df_new], ignore_index=True)\n",
    "        df_combined.drop_duplicates(inplace=True)\n",
    "        df_combined.to_csv(save_path, index=False, encoding=\"utf-8-sig\")\n",
    "    else:\n",
    "        df_new.to_csv(save_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✅ CSV 저장 완료 및 중복 제거: {save_path}\")\n",
    "\n",
    "# 6. 실행\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🔄 보이스피싱 대화 생성 중...\")\n",
    "    try:\n",
    "        scenario_plan = [\n",
    "            (\"authority impersonation\", 40),\n",
    "            (\"loan fraud\", 20),\n",
    "            (\"messenger phishing\", 20),\n",
    "            (\"parcel scam\", 20)\n",
    "        ]\n",
    "        batch_size = 5\n",
    "        save_path = \"./dataset/phishing_data.csv\"\n",
    "        start_index = get_next_start_index(save_path)\n",
    "        for scenario_type, total_count in scenario_plan:\n",
    "            for i in range(0, total_count, batch_size):\n",
    "                print(f\"생성 중: {scenario_type} {start_index} ~ {start_index+batch_size-1} (파일명 시작: phishing_{start_index:03d})\")\n",
    "                output = generate_phishing_dialogues(batch_size, start_index, scenario_type)\n",
    "                parse_and_save_csv_append_unique(output, save_path=save_path)\n",
    "                start_index += batch_size\n",
    "    except RateLimitError:\n",
    "        print(\"❌ RateLimitError: 쿼터 초과 또는 모델 접근 제한입니다. 잠시 후 재시도하거나 대시보드를 확인하세요.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류 발생: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9956651f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 보이스피싱 대화 생성 중...\n",
      "생성 중: authority impersonation 801 ~ 805 (파일명 시작: phishing_801)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: authority impersonation 806 ~ 810 (파일명 시작: phishing_806)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: authority impersonation 811 ~ 815 (파일명 시작: phishing_811)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: authority impersonation 816 ~ 820 (파일명 시작: phishing_816)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: authority impersonation 821 ~ 825 (파일명 시작: phishing_821)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: authority impersonation 826 ~ 830 (파일명 시작: phishing_826)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: authority impersonation 831 ~ 835 (파일명 시작: phishing_831)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: authority impersonation 836 ~ 840 (파일명 시작: phishing_836)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: loan fraud 841 ~ 845 (파일명 시작: phishing_841)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: loan fraud 846 ~ 850 (파일명 시작: phishing_846)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: loan fraud 851 ~ 855 (파일명 시작: phishing_851)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: loan fraud 856 ~ 860 (파일명 시작: phishing_856)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: messenger phishing 861 ~ 865 (파일명 시작: phishing_861)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: messenger phishing 866 ~ 870 (파일명 시작: phishing_866)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: messenger phishing 871 ~ 875 (파일명 시작: phishing_871)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: messenger phishing 876 ~ 880 (파일명 시작: phishing_876)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: parcel scam 881 ~ 885 (파일명 시작: phishing_881)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: parcel scam 886 ~ 890 (파일명 시작: phishing_886)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: parcel scam 891 ~ 895 (파일명 시작: phishing_891)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n",
      "생성 중: parcel scam 896 ~ 900 (파일명 시작: phishing_896)\n",
      "✅ CSV 저장 완료 및 중복 제거: ./dataset/phishing_data.csv\n"
     ]
    }
   ],
   "source": [
    "# GPT-4o 모델을 활용하여 보이스피싱 시나리오(기관사칭형, 대출빙자형, 메신저피싱형, 택배사기형)를 자동으로 생성하고, \n",
    "# 생성된 데이터를 중복 없이 CSV 파일로 저장하는 자동화 파이프라인입니다.\n",
    "# 각 시나리오 유형별로 대화 문장 수(13~15문장)를 엄격하게 제한하며, 피싱범(0)과 피해자(1)가 번갈아 대화하고, \n",
    "# 한 대화에는 한 가지 유형만 포함됩니다.\n",
    "# 대화 파일명은 phishing_001처럼 순차적으로 부여되고, 모든 대화에서 이름은 'OOO'만 사용합니다.\n",
    "# 각 유형별로 사칭 기관·대출 종류·메신저·택배사 등과 피해자 반응(의심, 순응, 당황, 저항 등)이 다양하게 포함되도록 \n",
    "# 프롬프트가 설계되어 있습니다.\n",
    "# 생성된 데이터는 기존 CSV와 합쳐 중복을 제거한 뒤 저장되며, RateLimitError 등 예외 상황도 처리합니다.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI, RateLimitError\n",
    "\n",
    "# 1. 환경 변수 로드 및 API 키 확인\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"❌ API 키가 로드되지 않았습니다. .env 파일을 확인하세요.\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# 2. 시나리오 유형별 시스템 프롬프트 (문장 수 조건 포함)\n",
    "system_prompt_dict = {\n",
    "    \"authority impersonation\": \"\"\"\n",
    "You are a financial crime investigation expert with 15 years of experience and a developer of voice phishing detection systems.\n",
    "Please create realistic and natural phone call scenarios for building a voice phishing detection dataset.\n",
    "\n",
    "Rules:\n",
    "1. Each conversation must consist of 13 to 15 sentences. Conversations with fewer than 13 sentences are not allowed under any circumstances.\n",
    "2. Each conversation must be of the 'authority impersonation' (기관사칭형) type only.\n",
    "3. The scammer (0) and the victim (1) alternate in the conversation.\n",
    "4. Only one conversation type per dialogue.\n",
    "5. Always use the name 'OOO' in all conversations (e.g., \"Hello, is this OOO?\").\n",
    "6. Make the conversations realistic, natural, and highly diverse. Vary the impersonated institutions (e.g., police, prosecutors, banks, tax office, insurance, etc.) and ensure the victim's responses are also diverse (suspicious, compliant, confused, resistant, etc.).\n",
    "7. Avoid duplication with previously generated conversations.\n",
    "8. Output the results in the following CSV format (without headers):\n",
    "\n",
    "phishing_001,authority impersonation,0,Hello, is this OOO? This is Inspector Kim from the Seoul Metropolitan Police.\n",
    "phishing_001,authority impersonation,1,Yes, that's me. What's going on?\n",
    "(Generate 5 conversations from phishing_001 to phishing_005.)\n",
    "\n",
    "Please output the conversation text in Korean.\n",
    "\"\"\",\n",
    "    \"loan fraud\": \"\"\"\n",
    "You are a financial crime investigation expert with 15 years of experience and a developer of voice phishing detection systems.\n",
    "Please create realistic and natural phone call scenarios for building a voice phishing detection dataset.\n",
    "\n",
    "Rules:\n",
    "1. Each conversation must consist of 13 to 15 sentences. Conversations with fewer than 13 sentences are not allowed under any circumstances.\n",
    "2. Each conversation must be of the 'loan fraud' (대출빙자형) type only.\n",
    "3. The scammer (0) and the victim (1) alternate in the conversation.\n",
    "4. Only one conversation type per dialogue.\n",
    "5. Always use the name 'OOO' in all conversations (e.g., \"Hello, is this OOO?\").\n",
    "6. Make the conversations realistic, natural, and highly diverse. Vary the loan types and ensure the victim's responses are also diverse (suspicious, compliant, confused, resistant, etc.).\n",
    "7. Avoid duplication with previously generated conversations.\n",
    "8. Output the results in the following CSV format (without headers):\n",
    "\n",
    "phishing_001,loan fraud,0,Hello, is this OOO? I am calling regarding a special loan offer.\n",
    "phishing_001,loan fraud,1,Yes? What is this about?\n",
    "(Generate 5 conversations from phishing_001 to phishing_005.)\n",
    "\n",
    "Please output the conversation text in Korean.\n",
    "\"\"\",\n",
    "    \"messenger phishing\": \"\"\"\n",
    "You are a financial crime investigation expert with 15 years of experience and a developer of voice phishing detection systems.\n",
    "Please create realistic and natural phone call scenarios for building a voice phishing detection dataset.\n",
    "\n",
    "Rules:\n",
    "1. Each conversation must consist of 13 to 15 sentences. Conversations with fewer than 13 sentences are not allowed under any circumstances.\n",
    "2. Each conversation must be of the 'messenger phishing' (메신저피싱형) type only.\n",
    "3. The scammer (0) and the victim (1) alternate in the conversation.\n",
    "4. Only one conversation type per dialogue.\n",
    "5. Always use the name 'OOO' in all conversations (e.g., \"Hello, is this OOO?\").\n",
    "6. Make the conversations realistic, natural, and highly diverse. Vary the impersonated messenger types and ensure the victim's responses are also diverse (suspicious, compliant, confused, resistant, etc.).\n",
    "7. Avoid duplication with previously generated conversations.\n",
    "8. Output the results in the following CSV format (without headers):\n",
    "\n",
    "phishing_001,messenger phishing,0,Hello, is this OOO? I'm contacting you through your messenger app.\n",
    "phishing_001,messenger phishing,1,Yes, this is OOO. Who is this?\n",
    "(Generate 5 conversations from phishing_001 to phishing_005.)\n",
    "\n",
    "Please output the conversation text in Korean.\n",
    "\"\"\",\n",
    "    \"parcel scam\": \"\"\"\n",
    "You are a financial crime investigation expert with 15 years of experience and a developer of voice phishing detection systems.\n",
    "Please create realistic and natural phone call scenarios for building a voice phishing detection dataset.\n",
    "\n",
    "Rules:\n",
    "1. Each conversation must consist of 13 to 15 sentences. Conversations with fewer than 13 sentences are not allowed under any circumstances.\n",
    "2. Each conversation must be of the 'parcel scam' (택배사기형) type only.\n",
    "3. The scammer (0) and the victim (1) alternate in the conversation.\n",
    "4. Only one conversation type per dialogue.\n",
    "5. Always use the name 'OOO' in all conversations (e.g., \"Hello, is this OOO?\").\n",
    "6. Make the conversations realistic, natural, and highly diverse. Vary the delivery companies and ensure the victim's responses are also diverse (suspicious, compliant, confused, resistant, etc.).\n",
    "7. Avoid duplication with previously generated conversations.\n",
    "8. Output the results in the following CSV format (without headers):\n",
    "\n",
    "phishing_001,parcel scam,0,Hello, is this OOO? I'm calling from the delivery service.\n",
    "phishing_001,parcel scam,1,Yes, this is OOO. Is there a problem with my parcel?\n",
    "(Generate 5 conversations from phishing_001 to phishing_005.)\n",
    "\n",
    "Please output the conversation text in Korean.\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "# 3. 기존 CSV에서 마지막 file_name의 번호를 읽어오는 함수\n",
    "def get_next_start_index(save_path=\"./dataset/phishing_data.csv\"):\n",
    "    if os.path.exists(save_path):\n",
    "        df = pd.read_csv(save_path)\n",
    "        max_idx = (\n",
    "            df[\"file_name\"]\n",
    "            .str.extract(r'phishing_(\\d+)')[0]\n",
    "            .dropna()\n",
    "            .astype(int)\n",
    "            .max()\n",
    "        )\n",
    "        return int(max_idx) + 1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# 4. GPT-4o로 시나리오 생성\n",
    "def generate_phishing_dialogues(n, start_index, scenario_type):\n",
    "    user_prompt = (\n",
    "        f\"Please generate {n} {scenario_type} voice phishing scenarios. \"\n",
    "        f\"File names should be assigned sequentially from phishing_{start_index:03d}.\"\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt_dict[scenario_type]},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.8\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# 5. 생성 결과를 CSV에 누적 저장(중복 제거)\n",
    "def parse_and_save_csv_append_unique(response_text, save_path=\"./dataset/phishing_data.csv\"):\n",
    "    lines = [line.strip() for line in response_text.strip().split(\"\\n\") if line and not line.startswith(\"file_name\")]\n",
    "    data = [line.split(\",\", maxsplit=3) for line in lines if len(line.split(\",\", maxsplit=3)) == 4]\n",
    "    df_new = pd.DataFrame(data, columns=[\"file_name\", \"conversation_type\", \"spk\", \"msg\"])\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    if os.path.exists(save_path):\n",
    "        df_existing = pd.read_csv(save_path)\n",
    "        df_combined = pd.concat([df_existing, df_new], ignore_index=True)\n",
    "        df_combined.drop_duplicates(inplace=True)\n",
    "        df_combined.to_csv(save_path, index=False, encoding=\"utf-8-sig\")\n",
    "    else:\n",
    "        df_new.to_csv(save_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✅ CSV 저장 완료 및 중복 제거: {save_path}\")\n",
    "\n",
    "# 6. 실행\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🔄 보이스피싱 대화 생성 중...\")\n",
    "    try:\n",
    "        scenario_plan = [\n",
    "            (\"authority impersonation\", 40),\n",
    "            (\"loan fraud\", 20),\n",
    "            (\"messenger phishing\", 20),\n",
    "            (\"parcel scam\", 20)\n",
    "        ]\n",
    "        batch_size = 5\n",
    "        save_path = \"./dataset/phishing_data.csv\"\n",
    "        start_index = get_next_start_index(save_path)\n",
    "        for scenario_type, total_count in scenario_plan:\n",
    "            for i in range(0, total_count, batch_size):\n",
    "                print(f\"생성 중: {scenario_type} {start_index} ~ {start_index+batch_size-1} (파일명 시작: phishing_{start_index:03d})\")\n",
    "                output = generate_phishing_dialogues(batch_size, start_index, scenario_type)\n",
    "                parse_and_save_csv_append_unique(output, save_path=save_path)\n",
    "                start_index += batch_size\n",
    "    except RateLimitError:\n",
    "        print(\"❌ RateLimitError: 쿼터 초과 또는 모델 접근 제한입니다. 잠시 후 재시도하거나 대시보드를 확인하세요.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류 발생: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2593bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "woogawooga_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
